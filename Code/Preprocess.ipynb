{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0c7a3399-dd30-4260-a4b4-cbcafe70065d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports:\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import string\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6a652163-4013-43e3-83b7-77ddcef29763",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in original data:\n",
    "df_train = pd.read_csv(\"../Data/train.csv\", encoding='utf-8')\n",
    "df_test = pd.read_csv(\"../Data/test.csv\", encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "db28e607-9d12-40cc-916e-6f48f7bd0c6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "abbreviations = {\n",
    "    \"$\" : \" dollar \",\n",
    "    \"€\" : \" euro \",\n",
    "    \"4ao\" : \"for adults only\",\n",
    "    \"a.m\" : \"before midday\",\n",
    "    \"a3\" : \"anytime anywhere anyplace\",\n",
    "    \"aamof\" : \"as a matter of fact\",\n",
    "    \"acct\" : \"account\",\n",
    "    \"adih\" : \"another day in hell\",\n",
    "    \"afaic\" : \"as far as i am concerned\",\n",
    "    \"afaict\" : \"as far as i can tell\",\n",
    "    \"afaik\" : \"as far as i know\",\n",
    "    \"afair\" : \"as far as i remember\",\n",
    "    \"afk\" : \"away from keyboard\",\n",
    "    \"app\" : \"application\",\n",
    "    \"approx\" : \"approximately\",\n",
    "    \"apps\" : \"applications\",\n",
    "    \"asap\" : \"as soon as possible\",\n",
    "    \"asl\" : \"age, sex, location\",\n",
    "    \"atk\" : \"at the keyboard\",\n",
    "    \"ave.\" : \"avenue\",\n",
    "    \"aymm\" : \"are you my mother\",\n",
    "    \"ayor\" : \"at your own risk\", \n",
    "    \"b&b\" : \"bed and breakfast\",\n",
    "    \"b+b\" : \"bed and breakfast\",\n",
    "    \"b.c\" : \"before christ\",\n",
    "    \"b2b\" : \"business to business\",\n",
    "    \"b2c\" : \"business to customer\",\n",
    "    \"b4\" : \"before\",\n",
    "    \"b4n\" : \"bye for now\",\n",
    "    \"b@u\" : \"back at you\",\n",
    "    \"bae\" : \"before anyone else\",\n",
    "    \"bak\" : \"back at keyboard\",\n",
    "    \"bbbg\" : \"bye bye be good\",\n",
    "    \"bbc\" : \"british broadcasting corporation\",\n",
    "    \"bbias\" : \"be back in a second\",\n",
    "    \"bbl\" : \"be back later\",\n",
    "    \"bbs\" : \"be back soon\",\n",
    "    \"be4\" : \"before\",\n",
    "    \"bfn\" : \"bye for now\",\n",
    "    \"blvd\" : \"boulevard\",\n",
    "    \"bout\" : \"about\",\n",
    "    \"brb\" : \"be right back\",\n",
    "    \"bros\" : \"brothers\",\n",
    "    \"brt\" : \"be right there\",\n",
    "    \"bsaaw\" : \"big smile and a wink\",\n",
    "    \"btw\" : \"by the way\",\n",
    "    \"bwl\" : \"bursting with laughter\",\n",
    "    \"c/o\" : \"care of\",\n",
    "    \"cet\" : \"central european time\",\n",
    "    \"cf\" : \"compare\",\n",
    "    \"cia\" : \"central intelligence agency\",\n",
    "    \"csl\" : \"can not stop laughing\",\n",
    "    \"cu\" : \"see you\",\n",
    "    \"cul8r\" : \"see you later\",\n",
    "    \"cv\" : \"curriculum vitae\",\n",
    "    \"cwot\" : \"complete waste of time\",\n",
    "    \"cya\" : \"see you\",\n",
    "    \"cyt\" : \"see you tomorrow\",\n",
    "    \"dae\" : \"does anyone else\",\n",
    "    \"dbmib\" : \"do not bother me i am busy\",\n",
    "    \"diy\" : \"do it yourself\",\n",
    "    \"dm\" : \"direct message\",\n",
    "    \"dwh\" : \"during work hours\",\n",
    "    \"e123\" : \"easy as one two three\",\n",
    "    \"eet\" : \"eastern european time\",\n",
    "    \"eg\" : \"example\",\n",
    "    \"embm\" : \"early morning business meeting\",\n",
    "    \"encl\" : \"enclosed\",\n",
    "    \"encl.\" : \"enclosed\",\n",
    "    \"etc\" : \"and so on\",\n",
    "    \"faq\" : \"frequently asked questions\",\n",
    "    \"fawc\" : \"for anyone who cares\",\n",
    "    \"fb\" : \"facebook\",\n",
    "    \"fc\" : \"fingers crossed\",\n",
    "    \"fig\" : \"figure\",\n",
    "    \"fimh\" : \"forever in my heart\", \n",
    "    \"ft.\" : \"feet\",\n",
    "    \"ft\" : \"featuring\",\n",
    "    \"ftl\" : \"for the loss\",\n",
    "    \"ftw\" : \"for the win\",\n",
    "    \"fwiw\" : \"for what it is worth\",\n",
    "    \"fyi\" : \"for your information\",\n",
    "    \"g9\" : \"genius\",\n",
    "    \"gahoy\" : \"get a hold of yourself\",\n",
    "    \"gal\" : \"get a life\",\n",
    "    \"gcse\" : \"general certificate of secondary education\",\n",
    "    \"gfn\" : \"gone for now\",\n",
    "    \"gg\" : \"good game\",\n",
    "    \"gl\" : \"good luck\",\n",
    "    \"glhf\" : \"good luck have fun\",\n",
    "    \"gmt\" : \"greenwich mean time\",\n",
    "    \"gmta\" : \"great minds think alike\",\n",
    "    \"gn\" : \"good night\",\n",
    "    \"g.o.a.t\" : \"greatest of all time\",\n",
    "    \"goat\" : \"greatest of all time\",\n",
    "    \"goi\" : \"get over it\",\n",
    "    \"gps\" : \"global positioning system\",\n",
    "    \"gr8\" : \"great\",\n",
    "    \"gratz\" : \"congratulations\",\n",
    "    \"gyal\" : \"girl\",\n",
    "    \"h&c\" : \"hot and cold\",\n",
    "    \"hp\" : \"horsepower\",\n",
    "    \"hr\" : \"hour\",\n",
    "    \"hrh\" : \"his royal highness\",\n",
    "    \"ht\" : \"height\",\n",
    "    \"ibrb\" : \"i will be right back\",\n",
    "    \"ic\" : \"i see\",\n",
    "    \"icq\" : \"i seek you\",\n",
    "    \"icymi\" : \"in case you missed it\",\n",
    "    \"idc\" : \"i do not care\",\n",
    "    \"idgadf\" : \"i do not give a damn fuck\",\n",
    "    \"idgaf\" : \"i do not give a fuck\",\n",
    "    \"idk\" : \"i do not know\",\n",
    "    \"ie\" : \"that is\",\n",
    "    \"i.e\" : \"that is\",\n",
    "    \"ifyp\" : \"i feel your pain\",\n",
    "    \"IG\" : \"instagram\",\n",
    "    \"iirc\" : \"if i remember correctly\",\n",
    "    \"ilu\" : \"i love you\",\n",
    "    \"ily\" : \"i love you\",\n",
    "    \"imho\" : \"in my humble opinion\",\n",
    "    \"imo\" : \"in my opinion\",\n",
    "    \"imu\" : \"i miss you\",\n",
    "    \"iow\" : \"in other words\",\n",
    "    \"irl\" : \"in real life\",\n",
    "    \"j4f\" : \"just for fun\",\n",
    "    \"jic\" : \"just in case\",\n",
    "    \"jk\" : \"just kidding\",\n",
    "    \"jsyk\" : \"just so you know\",\n",
    "    \"l8r\" : \"later\",\n",
    "    \"lb\" : \"pound\",\n",
    "    \"lbs\" : \"pounds\",\n",
    "    \"ldr\" : \"long distance relationship\",\n",
    "    \"lmao\" : \"laugh my ass off\",\n",
    "    \"lmfao\" : \"laugh my fucking ass off\",\n",
    "    \"lol\" : \"laughing out loud\",\n",
    "    \"ltd\" : \"limited\",\n",
    "    \"ltns\" : \"long time no see\",\n",
    "    \"m8\" : \"mate\",\n",
    "    \"mf\" : \"motherfucker\",\n",
    "    \"mfs\" : \"motherfuckers\",\n",
    "    \"mfw\" : \"my face when\",\n",
    "    \"mofo\" : \"motherfucker\",\n",
    "    \"mph\" : \"miles per hour\",\n",
    "    \"mr\" : \"mister\",\n",
    "    \"mrw\" : \"my reaction when\",\n",
    "    \"ms\" : \"miss\",\n",
    "    \"mte\" : \"my thoughts exactly\",\n",
    "    \"nagi\" : \"not a good idea\",\n",
    "    \"nbc\" : \"national broadcasting company\",\n",
    "    \"nbd\" : \"not big deal\",\n",
    "    \"nfs\" : \"not for sale\",\n",
    "    \"ngl\" : \"not going to lie\",\n",
    "    \"nhs\" : \"national health service\",\n",
    "    \"nrn\" : \"no reply necessary\",\n",
    "    \"nsfl\" : \"not safe for life\",\n",
    "    \"nsfw\" : \"not safe for work\",\n",
    "    \"nth\" : \"nice to have\",\n",
    "    \"nvr\" : \"never\",\n",
    "    \"nyc\" : \"new york city\",\n",
    "    \"oc\" : \"original content\",\n",
    "    \"og\" : \"original\",\n",
    "    \"ohp\" : \"overhead projector\",\n",
    "    \"oic\" : \"oh i see\",\n",
    "    \"omdb\" : \"over my dead body\",\n",
    "    \"omg\" : \"oh my god\",\n",
    "    \"omw\" : \"on my way\",\n",
    "    \"p.a\" : \"per annum\",\n",
    "    \"p.m\" : \"after midday\",\n",
    "    \"pm\" : \"prime minister\",\n",
    "    \"poc\" : \"people of color\",\n",
    "    \"pov\" : \"point of view\",\n",
    "    \"pp\" : \"pages\",\n",
    "    \"ppl\" : \"people\",\n",
    "    \"prw\" : \"parents are watching\",\n",
    "    \"ps\" : \"postscript\",\n",
    "    \"pt\" : \"point\",\n",
    "    \"ptb\" : \"please text back\",\n",
    "    \"pto\" : \"please turn over\",\n",
    "    \"qpsa\" : \"what happens\", #\"que pasa\",\n",
    "    \"ratchet\" : \"rude\",\n",
    "    \"rbtl\" : \"read between the lines\",\n",
    "    \"rlrt\" : \"real life retweet\", \n",
    "    \"rofl\" : \"rolling on the floor laughing\",\n",
    "    \"roflol\" : \"rolling on the floor laughing out loud\",\n",
    "    \"rotflmao\" : \"rolling on the floor laughing my ass off\",\n",
    "    \"rt\" : \"retweet\",\n",
    "    \"ruok\" : \"are you ok\",\n",
    "    \"sfw\" : \"safe for work\",\n",
    "    \"sk8\" : \"skate\",\n",
    "    \"smh\" : \"shake my head\",\n",
    "    \"sq\" : \"square\",\n",
    "    \"srsly\" : \"seriously\", \n",
    "    \"ssdd\" : \"same stuff different day\",\n",
    "    \"tbh\" : \"to be honest\",\n",
    "    \"tbs\" : \"tablespooful\",\n",
    "    \"tbsp\" : \"tablespooful\",\n",
    "    \"tfw\" : \"that feeling when\",\n",
    "    \"thks\" : \"thank you\",\n",
    "    \"tho\" : \"though\",\n",
    "    \"thx\" : \"thank you\",\n",
    "    \"tia\" : \"thanks in advance\",\n",
    "    \"til\" : \"today i learned\",\n",
    "    \"tl;dr\" : \"too long i did not read\",\n",
    "    \"tldr\" : \"too long i did not read\",\n",
    "    \"tmb\" : \"tweet me back\",\n",
    "    \"tntl\" : \"trying not to laugh\",\n",
    "    \"ttyl\" : \"talk to you later\",\n",
    "    \"u\" : \"you\",\n",
    "    \"u2\" : \"you too\",\n",
    "    \"u4e\" : \"yours for ever\",\n",
    "    \"utc\" : \"coordinated universal time\",\n",
    "    \"w/\" : \"with\",\n",
    "    \"w/o\" : \"without\",\n",
    "    \"w8\" : \"wait\",\n",
    "    \"wassup\" : \"what is up\",\n",
    "    \"wb\" : \"welcome back\",\n",
    "    \"wtf\" : \"what the fuck\",\n",
    "    \"wtg\" : \"way to go\",\n",
    "    \"wtpa\" : \"where the party at\",\n",
    "    \"wuf\" : \"where are you from\",\n",
    "    \"wuzup\" : \"what is up\",\n",
    "    \"wywh\" : \"wish you were here\",\n",
    "    \"yd\" : \"yard\",\n",
    "    \"ygtr\" : \"you got that right\",\n",
    "    \"ynk\" : \"you never know\",\n",
    "    \"zzz\" : \"sleeping bored and tired\"\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "626b361c-dc8d-4321-9813-e592f7474ee2",
   "metadata": {},
   "source": [
    "#### Helper Functions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9ea44b03-823f-4e36-8de7-61ada1529062",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change an abbreviation by its true meaning\n",
    "def word_abbrev(word):\n",
    "    return abbreviations[word.lower()] if word.lower() in abbreviations.keys() else word\n",
    "\n",
    "# Replace all abbreviations\n",
    "def replace_abbrev(text):\n",
    "    string = \"\"\n",
    "    for word in text.split():\n",
    "        string += word_abbrev(word) + \" \"        \n",
    "    return string\n",
    "\n",
    "# Remove all emojis, replace by EMOJI\n",
    "def remove_emoji(text):\n",
    "    stuff = re.compile(\n",
    "        '['\n",
    "        u'\\U0001F600-\\U0001F64F'\n",
    "        u'\\U0001F300-\\U0001F5FF'\n",
    "        u'\\U0001F680-\\U0001F6FF'\n",
    "        u'\\U0001F1E0-\\U0001F1FF'\n",
    "        u'\\U00002702-\\U000027B0'\n",
    "        u'\\U000024C2-\\U0001F251'\n",
    "        ']+',\n",
    "        flags=re.UNICODE)\n",
    "    return stuff.sub(r'', text)\n",
    "\n",
    "# Remove all punctuations\n",
    "def remove_punct(text):\n",
    "    stuff = str.maketrans('', '', string.punctuation)\n",
    "    return text.translate(stuff)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7f76893-39e2-4dcd-986e-5001f2f0bc6b",
   "metadata": {},
   "source": [
    "#### Feature Cleaning: \n",
    "\n",
    "Someone in the learning section for this competition took the effort to \"manually\" clean the text in these datasets, and most competitors ended up using this person's cleaning code. Thus, I will do the same to try and achieve the best performance. It should be noted that I made some adjustments to these cleaning steps. \n",
    "\n",
    "https://www.kaggle.com/code/gunesevitan/nlp-with-disaster-tweets-eda-cleaning-and-bert?cellIds=31&kernelSessionId=28164619"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "830146bc-76bf-43c8-8941-f71e8dd5448a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean(tweet): \n",
    "            \n",
    "    # Special characters\n",
    "    tweet = re.sub(r\"\\x89Û_\", \"\", tweet)\n",
    "    tweet = re.sub(r\"\\x89ÛÒ\", \"\", tweet)\n",
    "    tweet = re.sub(r\"\\x89ÛÓ\", \"\", tweet)\n",
    "    tweet = re.sub(r\"\\x89ÛÏWhen\", \"When\", tweet)\n",
    "    tweet = re.sub(r\"\\x89ÛÏ\", \"\", tweet)\n",
    "    tweet = re.sub(r\"China\\x89Ûªs\", \"China's\", tweet)\n",
    "    tweet = re.sub(r\"let\\x89Ûªs\", \"let's\", tweet)\n",
    "    tweet = re.sub(r\"\\x89Û÷\", \"\", tweet)\n",
    "    tweet = re.sub(r\"\\x89Ûª\", \"\", tweet)\n",
    "    tweet = re.sub(r\"\\x89Û\\x9d\", \"\", tweet)\n",
    "    tweet = re.sub(r\"å_\", \"\", tweet)\n",
    "    tweet = re.sub(r\"\\x89Û¢\", \"\", tweet)\n",
    "    tweet = re.sub(r\"\\x89Û¢åÊ\", \"\", tweet)\n",
    "    tweet = re.sub(r\"fromåÊwounds\", \"from wounds\", tweet)\n",
    "    tweet = re.sub(r\"åÊ\", \"\", tweet)\n",
    "    tweet = re.sub(r\"åÈ\", \"\", tweet)\n",
    "    tweet = re.sub(r\"JapÌ_n\", \"Japan\", tweet)    \n",
    "    tweet = re.sub(r\"Ì©\", \"e\", tweet)\n",
    "    tweet = re.sub(r\"å¨\", \"\", tweet)\n",
    "    tweet = re.sub(r\"SuruÌ¤\", \"Suruc\", tweet)\n",
    "    tweet = re.sub(r\"åÇ\", \"\", tweet)\n",
    "    tweet = re.sub(r\"å£3million\", \"3 million\", tweet)\n",
    "    tweet = re.sub(r\"åÀ\", \"\", tweet)\n",
    "    \n",
    "    # Contractions\n",
    "    tweet = re.sub(r\"he's\", \"he is\", tweet)\n",
    "    tweet = re.sub(r\"there's\", \"there is\", tweet)\n",
    "    tweet = re.sub(r\"We're\", \"We are\", tweet)\n",
    "    tweet = re.sub(r\"That's\", \"That is\", tweet)\n",
    "    tweet = re.sub(r\"won't\", \"will not\", tweet)\n",
    "    tweet = re.sub(r\"they're\", \"they are\", tweet)\n",
    "    tweet = re.sub(r\"Can't\", \"Cannot\", tweet)\n",
    "    tweet = re.sub(r\"wasn't\", \"was not\", tweet)\n",
    "    tweet = re.sub(r\"don\\x89Ûªt\", \"do not\", tweet)\n",
    "    tweet = re.sub(r\"aren't\", \"are not\", tweet)\n",
    "    tweet = re.sub(r\"isn't\", \"is not\", tweet)\n",
    "    tweet = re.sub(r\"What's\", \"What is\", tweet)\n",
    "    tweet = re.sub(r\"haven't\", \"have not\", tweet)\n",
    "    tweet = re.sub(r\"hasn't\", \"has not\", tweet)\n",
    "    tweet = re.sub(r\"There's\", \"There is\", tweet)\n",
    "    tweet = re.sub(r\"He's\", \"He is\", tweet)\n",
    "    tweet = re.sub(r\"It's\", \"It is\", tweet)\n",
    "    tweet = re.sub(r\"You're\", \"You are\", tweet)\n",
    "    tweet = re.sub(r\"I'M\", \"I am\", tweet)\n",
    "    tweet = re.sub(r\"shouldn't\", \"should not\", tweet)\n",
    "    tweet = re.sub(r\"wouldn't\", \"would not\", tweet)\n",
    "    tweet = re.sub(r\"i'm\", \"I am\", tweet)\n",
    "    tweet = re.sub(r\"I\\x89Ûªm\", \"I am\", tweet)\n",
    "    tweet = re.sub(r\"I'm\", \"I am\", tweet)\n",
    "    tweet = re.sub(r\"Isn't\", \"is not\", tweet)\n",
    "    tweet = re.sub(r\"Here's\", \"Here is\", tweet)\n",
    "    tweet = re.sub(r\"you've\", \"you have\", tweet)\n",
    "    tweet = re.sub(r\"you\\x89Ûªve\", \"you have\", tweet)\n",
    "    tweet = re.sub(r\"we're\", \"we are\", tweet)\n",
    "    tweet = re.sub(r\"what's\", \"what is\", tweet)\n",
    "    tweet = re.sub(r\"couldn't\", \"could not\", tweet)\n",
    "    tweet = re.sub(r\"we've\", \"we have\", tweet)\n",
    "    tweet = re.sub(r\"it\\x89Ûªs\", \"it is\", tweet)\n",
    "    tweet = re.sub(r\"doesn\\x89Ûªt\", \"does not\", tweet)\n",
    "    tweet = re.sub(r\"It\\x89Ûªs\", \"It is\", tweet)\n",
    "    tweet = re.sub(r\"Here\\x89Ûªs\", \"Here is\", tweet)\n",
    "    tweet = re.sub(r\"who's\", \"who is\", tweet)\n",
    "    tweet = re.sub(r\"I\\x89Ûªve\", \"I have\", tweet)\n",
    "    tweet = re.sub(r\"y'all\", \"you all\", tweet)\n",
    "    tweet = re.sub(r\"can\\x89Ûªt\", \"cannot\", tweet)\n",
    "    tweet = re.sub(r\"would've\", \"would have\", tweet)\n",
    "    tweet = re.sub(r\"it'll\", \"it will\", tweet)\n",
    "    tweet = re.sub(r\"we'll\", \"we will\", tweet)\n",
    "    tweet = re.sub(r\"wouldn\\x89Ûªt\", \"would not\", tweet)\n",
    "    tweet = re.sub(r\"We've\", \"We have\", tweet)\n",
    "    tweet = re.sub(r\"he'll\", \"he will\", tweet)\n",
    "    tweet = re.sub(r\"Y'all\", \"You all\", tweet)\n",
    "    tweet = re.sub(r\"Weren't\", \"Were not\", tweet)\n",
    "    tweet = re.sub(r\"Didn't\", \"Did not\", tweet)\n",
    "    tweet = re.sub(r\"they'll\", \"they will\", tweet)\n",
    "    tweet = re.sub(r\"they'd\", \"they would\", tweet)\n",
    "    tweet = re.sub(r\"DON'T\", \"DO NOT\", tweet)\n",
    "    tweet = re.sub(r\"That\\x89Ûªs\", \"That is\", tweet)\n",
    "    tweet = re.sub(r\"they've\", \"they have\", tweet)\n",
    "    tweet = re.sub(r\"i'd\", \"I would\", tweet)\n",
    "    tweet = re.sub(r\"should've\", \"should have\", tweet)\n",
    "    tweet = re.sub(r\"You\\x89Ûªre\", \"You are\", tweet)\n",
    "    tweet = re.sub(r\"where's\", \"where is\", tweet)\n",
    "    tweet = re.sub(r\"Don\\x89Ûªt\", \"Do not\", tweet)\n",
    "    tweet = re.sub(r\"we'd\", \"we would\", tweet)\n",
    "    tweet = re.sub(r\"i'll\", \"I will\", tweet)\n",
    "    tweet = re.sub(r\"weren't\", \"were not\", tweet)\n",
    "    tweet = re.sub(r\"They're\", \"They are\", tweet)\n",
    "    tweet = re.sub(r\"Can\\x89Ûªt\", \"Cannot\", tweet)\n",
    "    tweet = re.sub(r\"you\\x89Ûªll\", \"you will\", tweet)\n",
    "    tweet = re.sub(r\"I\\x89Ûªd\", \"I would\", tweet)\n",
    "    tweet = re.sub(r\"let's\", \"let us\", tweet)\n",
    "    tweet = re.sub(r\"it's\", \"it is\", tweet)\n",
    "    tweet = re.sub(r\"can't\", \"cannot\", tweet)\n",
    "    tweet = re.sub(r\"don't\", \"do not\", tweet)\n",
    "    tweet = re.sub(r\"you're\", \"you are\", tweet)\n",
    "    tweet = re.sub(r\"i've\", \"I have\", tweet)\n",
    "    tweet = re.sub(r\"that's\", \"that is\", tweet)\n",
    "    tweet = re.sub(r\"i'll\", \"I will\", tweet)\n",
    "    tweet = re.sub(r\"doesn't\", \"does not\", tweet)\n",
    "    tweet = re.sub(r\"i'd\", \"I would\", tweet)\n",
    "    tweet = re.sub(r\"didn't\", \"did not\", tweet)\n",
    "    tweet = re.sub(r\"ain't\", \"am not\", tweet)\n",
    "    tweet = re.sub(r\"you'll\", \"you will\", tweet)\n",
    "    tweet = re.sub(r\"I've\", \"I have\", tweet)\n",
    "    tweet = re.sub(r\"Don't\", \"do not\", tweet)\n",
    "    tweet = re.sub(r\"I'll\", \"I will\", tweet)\n",
    "    tweet = re.sub(r\"I'd\", \"I would\", tweet)\n",
    "    tweet = re.sub(r\"Let's\", \"Let us\", tweet)\n",
    "    tweet = re.sub(r\"you'd\", \"You would\", tweet)\n",
    "    tweet = re.sub(r\"It's\", \"It is\", tweet)\n",
    "    tweet = re.sub(r\"Ain't\", \"am not\", tweet)\n",
    "    tweet = re.sub(r\"Haven't\", \"Have not\", tweet)\n",
    "    tweet = re.sub(r\"Could've\", \"Could have\", tweet)\n",
    "    tweet = re.sub(r\"youve\", \"you have\", tweet)  \n",
    "    tweet = re.sub(r\"donå«t\", \"do not\", tweet)   \n",
    "            \n",
    "    # Character entity references\n",
    "    tweet = re.sub(r\"&gt;\", \">\", tweet)\n",
    "    tweet = re.sub(r\"&lt;\", \"<\", tweet)\n",
    "    tweet = re.sub(r\"&amp;\", \"&\", tweet)\n",
    "    \n",
    "    # Typos, slang and informal abbreviations\n",
    "    tweet = re.sub(r\"w/e\", \"whatever\", tweet)\n",
    "    tweet = re.sub(r\"w/\", \"with\", tweet)\n",
    "    tweet = re.sub(r\"USAgov\", \"USA government\", tweet)\n",
    "    tweet = re.sub(r\"recentlu\", \"recently\", tweet)\n",
    "    tweet = re.sub(r\"Ph0tos\", \"Photos\", tweet)\n",
    "    tweet = re.sub(r\"amirite\", \"am I right\", tweet)\n",
    "    tweet = re.sub(r\"exp0sed\", \"exposed\", tweet)\n",
    "    tweet = re.sub(r\"<3\", \"love\", tweet)\n",
    "    tweet = re.sub(r\"amageddon\", \"armageddon\", tweet)\n",
    "    tweet = re.sub(r\"Trfc\", \"Traffic\", tweet)\n",
    "    tweet = re.sub(r\"8/5/2015\", \"2015-08-05\", tweet)\n",
    "    tweet = re.sub(r\"WindStorm\", \"Wind Storm\", tweet)\n",
    "    tweet = re.sub(r\"8/6/2015\", \"2015-08-06\", tweet)\n",
    "    tweet = re.sub(r\"10:38PM\", \"10:38 PM\", tweet)\n",
    "    tweet = re.sub(r\"10:30pm\", \"10:30 PM\", tweet)\n",
    "    tweet = re.sub(r\"16yr\", \"16 year\", tweet)\n",
    "    tweet = re.sub(r\"lmao\", \"laughing my ass off\", tweet)   \n",
    "    tweet = re.sub(r\"TRAUMATISED\", \"traumatized\", tweet)\n",
    "    \n",
    "    # Hashtags and usernames\n",
    "    tweet = re.sub(r\"IranDeal\", \"Iran Deal\", tweet)\n",
    "    tweet = re.sub(r\"ArianaGrande\", \"Ariana Grande\", tweet)\n",
    "    tweet = re.sub(r\"camilacabello97\", \"camila cabello\", tweet) \n",
    "    tweet = re.sub(r\"RondaRousey\", \"Ronda Rousey\", tweet)     \n",
    "    tweet = re.sub(r\"MTVHottest\", \"MTV Hottest\", tweet)\n",
    "    tweet = re.sub(r\"TrapMusic\", \"Trap Music\", tweet)\n",
    "    tweet = re.sub(r\"ProphetMuhammad\", \"Prophet Muhammad\", tweet)\n",
    "    tweet = re.sub(r\"PantherAttack\", \"Panther Attack\", tweet)\n",
    "    tweet = re.sub(r\"StrategicPatience\", \"Strategic Patience\", tweet)\n",
    "    tweet = re.sub(r\"socialnews\", \"social news\", tweet)\n",
    "    tweet = re.sub(r\"NASAHurricane\", \"NASA Hurricane\", tweet)\n",
    "    tweet = re.sub(r\"onlinecommunities\", \"online communities\", tweet)\n",
    "    tweet = re.sub(r\"humanconsumption\", \"human consumption\", tweet)\n",
    "    tweet = re.sub(r\"Typhoon-Devastated\", \"Typhoon Devastated\", tweet)\n",
    "    tweet = re.sub(r\"Meat-Loving\", \"Meat Loving\", tweet)\n",
    "    tweet = re.sub(r\"facialabuse\", \"facial abuse\", tweet)\n",
    "    tweet = re.sub(r\"LakeCounty\", \"Lake County\", tweet)\n",
    "    tweet = re.sub(r\"BeingAuthor\", \"Being Author\", tweet)\n",
    "    tweet = re.sub(r\"withheavenly\", \"with heavenly\", tweet)\n",
    "    tweet = re.sub(r\"thankU\", \"thank you\", tweet)\n",
    "    tweet = re.sub(r\"iTunesMusic\", \"iTunes Music\", tweet)\n",
    "    tweet = re.sub(r\"OffensiveContent\", \"Offensive Content\", tweet)\n",
    "    tweet = re.sub(r\"WorstSummerJob\", \"Worst Summer Job\", tweet)\n",
    "    tweet = re.sub(r\"HarryBeCareful\", \"Harry Be Careful\", tweet)\n",
    "    tweet = re.sub(r\"NASASolarSystem\", \"NASA Solar System\", tweet)\n",
    "    tweet = re.sub(r\"animalrescue\", \"animal rescue\", tweet)\n",
    "    tweet = re.sub(r\"KurtSchlichter\", \"Kurt Schlichter\", tweet)\n",
    "    tweet = re.sub(r\"aRmageddon\", \"armageddon\", tweet)\n",
    "    tweet = re.sub(r\"Throwingknifes\", \"Throwing knives\", tweet)\n",
    "    tweet = re.sub(r\"GodsLove\", \"God's Love\", tweet)\n",
    "    tweet = re.sub(r\"bookboost\", \"book boost\", tweet)\n",
    "    tweet = re.sub(r\"ibooklove\", \"I book love\", tweet)\n",
    "    tweet = re.sub(r\"NestleIndia\", \"Nestle India\", tweet)\n",
    "    tweet = re.sub(r\"realDonaldTrump\", \"Donald Trump\", tweet)\n",
    "    tweet = re.sub(r\"DavidVonderhaar\", \"David Vonderhaar\", tweet)\n",
    "    tweet = re.sub(r\"CecilTheLion\", \"Cecil The Lion\", tweet)\n",
    "    tweet = re.sub(r\"weathernetwork\", \"weather network\", tweet)\n",
    "    tweet = re.sub(r\"withBioterrorism&use\", \"with Bioterrorism & use\", tweet)\n",
    "    tweet = re.sub(r\"Hostage&2\", \"Hostage & 2\", tweet)\n",
    "    tweet = re.sub(r\"GOPDebate\", \"GOP Debate\", tweet)\n",
    "    tweet = re.sub(r\"RickPerry\", \"Rick Perry\", tweet)\n",
    "    tweet = re.sub(r\"frontpage\", \"front page\", tweet)\n",
    "    tweet = re.sub(r\"NewsInTweets\", \"News In Tweets\", tweet)\n",
    "    tweet = re.sub(r\"ViralSpell\", \"Viral Spell\", tweet)\n",
    "    tweet = re.sub(r\"til_now\", \"until now\", tweet)\n",
    "    tweet = re.sub(r\"volcanoinRussia\", \"volcano in Russia\", tweet)\n",
    "    tweet = re.sub(r\"ZippedNews\", \"Zipped News\", tweet)\n",
    "    tweet = re.sub(r\"MicheleBachman\", \"Michele Bachman\", tweet)\n",
    "    tweet = re.sub(r\"53inch\", \"53 inch\", tweet)\n",
    "    tweet = re.sub(r\"KerrickTrial\", \"Kerrick Trial\", tweet)\n",
    "    tweet = re.sub(r\"abstorm\", \"Alberta Storm\", tweet)\n",
    "    tweet = re.sub(r\"Beyhive\", \"Beyonce hive\", tweet)\n",
    "    tweet = re.sub(r\"IDFire\", \"Idaho Fire\", tweet)\n",
    "    tweet = re.sub(r\"DETECTADO\", \"Detected\", tweet)\n",
    "    tweet = re.sub(r\"RockyFire\", \"Rocky Fire\", tweet)\n",
    "    tweet = re.sub(r\"Listen/Buy\", \"Listen / Buy\", tweet)\n",
    "    tweet = re.sub(r\"NickCannon\", \"Nick Cannon\", tweet)\n",
    "    tweet = re.sub(r\"FaroeIslands\", \"Faroe Islands\", tweet)\n",
    "    tweet = re.sub(r\"yycstorm\", \"Calgary Storm\", tweet)\n",
    "    tweet = re.sub(r\"IDPs:\", \"Internally Displaced People :\", tweet)\n",
    "    tweet = re.sub(r\"ArtistsUnited\", \"Artists United\", tweet)\n",
    "    tweet = re.sub(r\"ClaytonBryant\", \"Clayton Bryant\", tweet)\n",
    "    tweet = re.sub(r\"jimmyfallon\", \"jimmy fallon\", tweet)\n",
    "    tweet = re.sub(r\"justinbieber\", \"justin bieber\", tweet)  \n",
    "    tweet = re.sub(r\"UTC2015\", \"UTC 2015\", tweet)\n",
    "    tweet = re.sub(r\"Time2015\", \"Time 2015\", tweet)\n",
    "    tweet = re.sub(r\"djicemoon\", \"dj icemoon\", tweet)\n",
    "    tweet = re.sub(r\"LivingSafely\", \"Living Safely\", tweet)\n",
    "    tweet = re.sub(r\"FIFA16\", \"Fifa 2016\", tweet)\n",
    "    tweet = re.sub(r\"thisiswhywecanthavenicethings\", \"this is why we cannot have nice things\", tweet)\n",
    "    tweet = re.sub(r\"bbcnews\", \"bbc news\", tweet)\n",
    "    tweet = re.sub(r\"UndergroundRailraod\", \"Underground Railraod\", tweet)\n",
    "    tweet = re.sub(r\"c4news\", \"c4 news\", tweet)\n",
    "    tweet = re.sub(r\"OBLITERATION\", \"obliteration\", tweet)\n",
    "    tweet = re.sub(r\"MUDSLIDE\", \"mudslide\", tweet)\n",
    "    tweet = re.sub(r\"NoSurrender\", \"No Surrender\", tweet)\n",
    "    tweet = re.sub(r\"NotExplained\", \"Not Explained\", tweet)\n",
    "    tweet = re.sub(r\"greatbritishbakeoff\", \"great british bake off\", tweet)\n",
    "    tweet = re.sub(r\"LondonFire\", \"London Fire\", tweet)\n",
    "    tweet = re.sub(r\"KOTAWeather\", \"KOTA Weather\", tweet)\n",
    "    tweet = re.sub(r\"LuchaUnderground\", \"Lucha Underground\", tweet)\n",
    "    tweet = re.sub(r\"KOIN6News\", \"KOIN 6 News\", tweet)\n",
    "    tweet = re.sub(r\"LiveOnK2\", \"Live On K2\", tweet)\n",
    "    tweet = re.sub(r\"9NewsGoldCoast\", \"9 News Gold Coast\", tweet)\n",
    "    tweet = re.sub(r\"nikeplus\", \"nike plus\", tweet)\n",
    "    tweet = re.sub(r\"david_cameron\", \"David Cameron\", tweet)\n",
    "    tweet = re.sub(r\"peterjukes\", \"Peter Jukes\", tweet)\n",
    "    tweet = re.sub(r\"JamesMelville\", \"James Melville\", tweet)\n",
    "    tweet = re.sub(r\"megynkelly\", \"Megyn Kelly\", tweet)\n",
    "    tweet = re.sub(r\"cnewslive\", \"C News Live\", tweet)\n",
    "    tweet = re.sub(r\"JamaicaObserver\", \"Jamaica Observer\", tweet)\n",
    "    tweet = re.sub(r\"TweetLikeItsSeptember11th2001\", \"Tweet like it is september 11th 2001\", tweet)\n",
    "    tweet = re.sub(r\"cbplawyers\", \"cbp lawyers\", tweet)\n",
    "    tweet = re.sub(r\"fewmoretweets\", \"few more tweets\", tweet)\n",
    "    tweet = re.sub(r\"BlackLivesMatter\", \"Black Lives Matter\", tweet)\n",
    "    tweet = re.sub(r\"cjoyner\", \"Chris Joyner\", tweet)\n",
    "    tweet = re.sub(r\"ENGvAUS\", \"England vs Australia\", tweet)\n",
    "    tweet = re.sub(r\"ScottWalker\", \"Scott Walker\", tweet)\n",
    "    tweet = re.sub(r\"MikeParrActor\", \"Michael Parr\", tweet)\n",
    "    tweet = re.sub(r\"4PlayThursdays\", \"Foreplay Thursdays\", tweet)\n",
    "    tweet = re.sub(r\"TGF2015\", \"Tontitown Grape Festival\", tweet)\n",
    "    tweet = re.sub(r\"realmandyrain\", \"Mandy Rain\", tweet)\n",
    "    tweet = re.sub(r\"GraysonDolan\", \"Grayson Dolan\", tweet)\n",
    "    tweet = re.sub(r\"ApolloBrown\", \"Apollo Brown\", tweet)\n",
    "    tweet = re.sub(r\"saddlebrooke\", \"Saddlebrooke\", tweet)\n",
    "    tweet = re.sub(r\"TontitownGrape\", \"Tontitown Grape\", tweet)\n",
    "    tweet = re.sub(r\"AbbsWinston\", \"Abbs Winston\", tweet)\n",
    "    tweet = re.sub(r\"ShaunKing\", \"Shaun King\", tweet)\n",
    "    tweet = re.sub(r\"MeekMill\", \"Meek Mill\", tweet)\n",
    "    tweet = re.sub(r\"TornadoGiveaway\", \"Tornado Giveaway\", tweet)\n",
    "    tweet = re.sub(r\"GRupdates\", \"GR updates\", tweet)\n",
    "    tweet = re.sub(r\"SouthDowns\", \"South Downs\", tweet)\n",
    "    tweet = re.sub(r\"braininjury\", \"brain injury\", tweet)\n",
    "    tweet = re.sub(r\"auspol\", \"Australian politics\", tweet)\n",
    "    tweet = re.sub(r\"PlannedParenthood\", \"Planned Parenthood\", tweet)\n",
    "    tweet = re.sub(r\"calgaryweather\", \"Calgary Weather\", tweet)\n",
    "    tweet = re.sub(r\"weallheartonedirection\", \"we all heart one direction\", tweet)\n",
    "    tweet = re.sub(r\"edsheeran\", \"Ed Sheeran\", tweet)\n",
    "    tweet = re.sub(r\"TrueHeroes\", \"True Heroes\", tweet)\n",
    "    tweet = re.sub(r\"S3XLEAK\", \"sex leak\", tweet)\n",
    "    tweet = re.sub(r\"ComplexMag\", \"Complex Magazine\", tweet)\n",
    "    tweet = re.sub(r\"TheAdvocateMag\", \"The Advocate Magazine\", tweet)\n",
    "    tweet = re.sub(r\"CityofCalgary\", \"City of Calgary\", tweet)\n",
    "    tweet = re.sub(r\"EbolaOutbreak\", \"Ebola Outbreak\", tweet)\n",
    "    tweet = re.sub(r\"SummerFate\", \"Summer Fate\", tweet)\n",
    "    tweet = re.sub(r\"RAmag\", \"Royal Academy Magazine\", tweet)\n",
    "    tweet = re.sub(r\"offers2go\", \"offers to go\", tweet)\n",
    "    tweet = re.sub(r\"foodscare\", \"food scare\", tweet)\n",
    "    tweet = re.sub(r\"MNPDNashville\", \"Metropolitan Nashville Police Department\", tweet)\n",
    "    tweet = re.sub(r\"TfLBusAlerts\", \"TfL Bus Alerts\", tweet)\n",
    "    tweet = re.sub(r\"GamerGate\", \"Gamer Gate\", tweet)\n",
    "    tweet = re.sub(r\"IHHen\", \"Humanitarian Relief\", tweet)\n",
    "    tweet = re.sub(r\"spinningbot\", \"spinning bot\", tweet)\n",
    "    tweet = re.sub(r\"ModiMinistry\", \"Modi Ministry\", tweet)\n",
    "    tweet = re.sub(r\"TAXIWAYS\", \"taxi ways\", tweet)\n",
    "    tweet = re.sub(r\"Calum5SOS\", \"Calum Hood\", tweet)\n",
    "    tweet = re.sub(r\"po_st\", \"po.st\", tweet)\n",
    "    tweet = re.sub(r\"scoopit\", \"scoop.it\", tweet)\n",
    "    tweet = re.sub(r\"UltimaLucha\", \"Ultima Lucha\", tweet)\n",
    "    tweet = re.sub(r\"JonathanFerrell\", \"Jonathan Ferrell\", tweet)\n",
    "    tweet = re.sub(r\"aria_ahrary\", \"Aria Ahrary\", tweet)\n",
    "    tweet = re.sub(r\"rapidcity\", \"Rapid City\", tweet)\n",
    "    tweet = re.sub(r\"OutBid\", \"outbid\", tweet)\n",
    "    tweet = re.sub(r\"lavenderpoetrycafe\", \"lavender poetry cafe\", tweet)\n",
    "    tweet = re.sub(r\"EudryLantiqua\", \"Eudry Lantiqua\", tweet)\n",
    "    tweet = re.sub(r\"15PM\", \"15 PM\", tweet)\n",
    "    tweet = re.sub(r\"OriginalFunko\", \"Funko\", tweet)\n",
    "    tweet = re.sub(r\"rightwaystan\", \"Richard Tan\", tweet)\n",
    "    tweet = re.sub(r\"CindyNoonan\", \"Cindy Noonan\", tweet)\n",
    "    tweet = re.sub(r\"RT_America\", \"RT America\", tweet)\n",
    "    tweet = re.sub(r\"narendramodi\", \"Narendra Modi\", tweet)\n",
    "    tweet = re.sub(r\"BakeOffFriends\", \"Bake Off Friends\", tweet)\n",
    "    tweet = re.sub(r\"TeamHendrick\", \"Hendrick Motorsports\", tweet)\n",
    "    tweet = re.sub(r\"alexbelloli\", \"Alex Belloli\", tweet)\n",
    "    tweet = re.sub(r\"itsjustinstuart\", \"Justin Stuart\", tweet)\n",
    "    tweet = re.sub(r\"gunsense\", \"gun sense\", tweet)\n",
    "    tweet = re.sub(r\"DebateQuestionsWeWantToHear\", \"debate questions we want to hear\", tweet)\n",
    "    tweet = re.sub(r\"RoyalCarribean\", \"Royal Carribean\", tweet)\n",
    "    tweet = re.sub(r\"samanthaturne19\", \"Samantha Turner\", tweet)\n",
    "    tweet = re.sub(r\"JonVoyage\", \"Jon Stewart\", tweet)\n",
    "    tweet = re.sub(r\"renew911health\", \"renew 911 health\", tweet)\n",
    "    tweet = re.sub(r\"SuryaRay\", \"Surya Ray\", tweet)\n",
    "    tweet = re.sub(r\"pattonoswalt\", \"Patton Oswalt\", tweet)\n",
    "    tweet = re.sub(r\"minhazmerchant\", \"Minhaz Merchant\", tweet)\n",
    "    tweet = re.sub(r\"TLVFaces\", \"Israel Diaspora Coalition\", tweet)\n",
    "    tweet = re.sub(r\"pmarca\", \"Marc Andreessen\", tweet)\n",
    "    tweet = re.sub(r\"pdx911\", \"Portland Police\", tweet)\n",
    "    tweet = re.sub(r\"jamaicaplain\", \"Jamaica Plain\", tweet)\n",
    "    tweet = re.sub(r\"Japton\", \"Arkansas\", tweet)\n",
    "    tweet = re.sub(r\"RouteComplex\", \"Route Complex\", tweet)\n",
    "    tweet = re.sub(r\"INSubcontinent\", \"Indian Subcontinent\", tweet)\n",
    "    tweet = re.sub(r\"NJTurnpike\", \"New Jersey Turnpike\", tweet)\n",
    "    tweet = re.sub(r\"Politifiact\", \"PolitiFact\", tweet)\n",
    "    tweet = re.sub(r\"Hiroshima70\", \"Hiroshima\", tweet)\n",
    "    tweet = re.sub(r\"GMMBC\", \"Greater Mt Moriah Baptist Church\", tweet)\n",
    "    tweet = re.sub(r\"versethe\", \"verse the\", tweet)\n",
    "    tweet = re.sub(r\"TubeStrike\", \"Tube Strike\", tweet)\n",
    "    tweet = re.sub(r\"MissionHills\", \"Mission Hills\", tweet)\n",
    "    tweet = re.sub(r\"ProtectDenaliWolves\", \"Protect Denali Wolves\", tweet)\n",
    "    tweet = re.sub(r\"NANKANA\", \"Nankana\", tweet)\n",
    "    tweet = re.sub(r\"SAHIB\", \"Sahib\", tweet)\n",
    "    tweet = re.sub(r\"PAKPATTAN\", \"Pakpattan\", tweet)\n",
    "    tweet = re.sub(r\"Newz_Sacramento\", \"News Sacramento\", tweet)\n",
    "    tweet = re.sub(r\"gofundme\", \"go fund me\", tweet)\n",
    "    tweet = re.sub(r\"pmharper\", \"Stephen Harper\", tweet)\n",
    "    tweet = re.sub(r\"IvanBerroa\", \"Ivan Berroa\", tweet)\n",
    "    tweet = re.sub(r\"LosDelSonido\", \"Los Del Sonido\", tweet)\n",
    "    tweet = re.sub(r\"bancodeseries\", \"banco de series\", tweet)\n",
    "    tweet = re.sub(r\"timkaine\", \"Tim Kaine\", tweet)\n",
    "    tweet = re.sub(r\"IdentityTheft\", \"Identity Theft\", tweet)\n",
    "    tweet = re.sub(r\"AllLivesMatter\", \"All Lives Matter\", tweet)\n",
    "    tweet = re.sub(r\"mishacollins\", \"Misha Collins\", tweet)\n",
    "    tweet = re.sub(r\"BillNeelyNBC\", \"Bill Neely\", tweet)\n",
    "    tweet = re.sub(r\"BeClearOnCancer\", \"be clear on cancer\", tweet)\n",
    "    tweet = re.sub(r\"Kowing\", \"Knowing\", tweet)\n",
    "    tweet = re.sub(r\"ScreamQueens\", \"Scream Queens\", tweet)\n",
    "    tweet = re.sub(r\"AskCharley\", \"Ask Charley\", tweet)\n",
    "    tweet = re.sub(r\"BlizzHeroes\", \"Heroes of the Storm\", tweet)\n",
    "    tweet = re.sub(r\"BradleyBrad47\", \"Bradley Brad\", tweet)\n",
    "    tweet = re.sub(r\"HannaPH\", \"Typhoon Hanna\", tweet)\n",
    "    tweet = re.sub(r\"meinlcymbals\", \"MEINL Cymbals\", tweet)\n",
    "    tweet = re.sub(r\"Ptbo\", \"Peterborough\", tweet)\n",
    "    tweet = re.sub(r\"cnnbrk\", \"CNN Breaking News\", tweet)\n",
    "    tweet = re.sub(r\"IndianNews\", \"Indian News\", tweet)\n",
    "    tweet = re.sub(r\"savebees\", \"save bees\", tweet)\n",
    "    tweet = re.sub(r\"GreenHarvard\", \"Green Harvard\", tweet)\n",
    "    tweet = re.sub(r\"StandwithPP\", \"Stand with planned parenthood\", tweet)\n",
    "    tweet = re.sub(r\"hermancranston\", \"Herman Cranston\", tweet)\n",
    "    tweet = re.sub(r\"WMUR9\", \"WMUR-TV\", tweet)\n",
    "    tweet = re.sub(r\"RockBottomRadFM\", \"Rock Bottom Radio\", tweet)\n",
    "    tweet = re.sub(r\"ameenshaikh3\", \"Ameen Shaikh\", tweet)\n",
    "    tweet = re.sub(r\"ProSyn\", \"Project Syndicate\", tweet)\n",
    "    tweet = re.sub(r\"Daesh\", \"ISIS\", tweet)\n",
    "    tweet = re.sub(r\"s2g\", \"swear to god\", tweet)\n",
    "    tweet = re.sub(r\"listenlive\", \"listen live\", tweet)\n",
    "    tweet = re.sub(r\"CDCgov\", \"Centers for Disease Control and Prevention\", tweet)\n",
    "    tweet = re.sub(r\"FoxNew\", \"Fox News\", tweet)\n",
    "    tweet = re.sub(r\"CBSBigBrother\", \"Big Brother\", tweet)\n",
    "    tweet = re.sub(r\"JulieDiCaro\", \"Julie DiCaro\", tweet)\n",
    "    tweet = re.sub(r\"theadvocatemag\", \"The Advocate Magazine\", tweet)\n",
    "    tweet = re.sub(r\"RohnertParkDPS\", \"Rohnert Park Police Department\", tweet)\n",
    "    tweet = re.sub(r\"THISIZBWRIGHT\", \"Bonnie Wright\", tweet)\n",
    "    tweet = re.sub(r\"Popularmmos\", \"Popular MMOs\", tweet)\n",
    "    tweet = re.sub(r\"WildHorses\", \"Wild Horses\", tweet)\n",
    "    tweet = re.sub(r\"FantasticFour\", \"Fantastic Four\", tweet)\n",
    "    tweet = re.sub(r\"HORNDALE\", \"Horndale\", tweet)\n",
    "    tweet = re.sub(r\"PINER\", \"Piner\", tweet)\n",
    "    tweet = re.sub(r\"BathAndNorthEastSomerset\", \"Bath and North East Somerset\", tweet)\n",
    "    tweet = re.sub(r\"thatswhatfriendsarefor\", \"that is what friends are for\", tweet)\n",
    "    tweet = re.sub(r\"residualincome\", \"residual income\", tweet)\n",
    "    tweet = re.sub(r\"YahooNewsDigest\", \"Yahoo News Digest\", tweet)\n",
    "    tweet = re.sub(r\"MalaysiaAirlines\", \"Malaysia Airlines\", tweet)\n",
    "    tweet = re.sub(r\"AmazonDeals\", \"Amazon Deals\", tweet)\n",
    "    tweet = re.sub(r\"MissCharleyWebb\", \"Charley Webb\", tweet)\n",
    "    tweet = re.sub(r\"shoalstraffic\", \"shoals traffic\", tweet)\n",
    "    tweet = re.sub(r\"GeorgeFoster72\", \"George Foster\", tweet)\n",
    "    tweet = re.sub(r\"pop2015\", \"pop 2015\", tweet)\n",
    "    tweet = re.sub(r\"_PokemonCards_\", \"Pokemon Cards\", tweet)\n",
    "    tweet = re.sub(r\"DianneG\", \"Dianne Gallagher\", tweet)\n",
    "    tweet = re.sub(r\"KashmirConflict\", \"Kashmir Conflict\", tweet)\n",
    "    tweet = re.sub(r\"BritishBakeOff\", \"British Bake Off\", tweet)\n",
    "    tweet = re.sub(r\"FreeKashmir\", \"Free Kashmir\", tweet)\n",
    "    tweet = re.sub(r\"mattmosley\", \"Matt Mosley\", tweet)\n",
    "    tweet = re.sub(r\"BishopFred\", \"Bishop Fred\", tweet)\n",
    "    tweet = re.sub(r\"EndConflict\", \"End Conflict\", tweet)\n",
    "    tweet = re.sub(r\"EndOccupation\", \"End Occupation\", tweet)\n",
    "    tweet = re.sub(r\"UNHEALED\", \"unhealed\", tweet)\n",
    "    tweet = re.sub(r\"CharlesDagnall\", \"Charles Dagnall\", tweet)\n",
    "    tweet = re.sub(r\"Latestnews\", \"Latest news\", tweet)\n",
    "    tweet = re.sub(r\"KindleCountdown\", \"Kindle Countdown\", tweet)\n",
    "    tweet = re.sub(r\"NoMoreHandouts\", \"No More Handouts\", tweet)\n",
    "    tweet = re.sub(r\"datingtips\", \"dating tips\", tweet)\n",
    "    tweet = re.sub(r\"charlesadler\", \"Charles Adler\", tweet)\n",
    "    tweet = re.sub(r\"twia\", \"Texas Windstorm Insurance Association\", tweet)\n",
    "    tweet = re.sub(r\"txlege\", \"Texas Legislature\", tweet)\n",
    "    tweet = re.sub(r\"WindstormInsurer\", \"Windstorm Insurer\", tweet)\n",
    "    tweet = re.sub(r\"Newss\", \"News\", tweet)\n",
    "    tweet = re.sub(r\"hempoil\", \"hemp oil\", tweet)\n",
    "    tweet = re.sub(r\"CommoditiesAre\", \"Commodities are\", tweet)\n",
    "    tweet = re.sub(r\"tubestrike\", \"tube strike\", tweet)\n",
    "    tweet = re.sub(r\"JoeNBC\", \"Joe Scarborough\", tweet)\n",
    "    tweet = re.sub(r\"LiteraryCakes\", \"Literary Cakes\", tweet)\n",
    "    tweet = re.sub(r\"TI5\", \"The International 5\", tweet)\n",
    "    tweet = re.sub(r\"thehill\", \"the hill\", tweet)\n",
    "    tweet = re.sub(r\"3others\", \"3 others\", tweet)\n",
    "    tweet = re.sub(r\"stighefootball\", \"Sam Tighe\", tweet)\n",
    "    tweet = re.sub(r\"whatstheimportantvideo\", \"what is the important video\", tweet)\n",
    "    tweet = re.sub(r\"ClaudioMeloni\", \"Claudio Meloni\", tweet)\n",
    "    tweet = re.sub(r\"DukeSkywalker\", \"Duke Skywalker\", tweet)\n",
    "    tweet = re.sub(r\"carsonmwr\", \"Fort Carson\", tweet)\n",
    "    tweet = re.sub(r\"offdishduty\", \"off dish duty\", tweet)\n",
    "    tweet = re.sub(r\"andword\", \"and word\", tweet)\n",
    "    tweet = re.sub(r\"rhodeisland\", \"Rhode Island\", tweet)\n",
    "    tweet = re.sub(r\"easternoregon\", \"Eastern Oregon\", tweet)\n",
    "    tweet = re.sub(r\"WAwildfire\", \"Washington Wildfire\", tweet)\n",
    "    tweet = re.sub(r\"fingerrockfire\", \"Finger Rock Fire\", tweet)\n",
    "    tweet = re.sub(r\"57am\", \"57 am\", tweet)\n",
    "    tweet = re.sub(r\"fingerrockfire\", \"Finger Rock Fire\", tweet)\n",
    "    tweet = re.sub(r\"JacobHoggard\", \"Jacob Hoggard\", tweet)\n",
    "    tweet = re.sub(r\"newnewnew\", \"new new new\", tweet)\n",
    "    tweet = re.sub(r\"under50\", \"under 50\", tweet)\n",
    "    tweet = re.sub(r\"getitbeforeitsgone\", \"get it before it is gone\", tweet)\n",
    "    tweet = re.sub(r\"freshoutofthebox\", \"fresh out of the box\", tweet)\n",
    "    tweet = re.sub(r\"amwriting\", \"am writing\", tweet)\n",
    "    tweet = re.sub(r\"Bokoharm\", \"Boko Haram\", tweet)\n",
    "    tweet = re.sub(r\"Nowlike\", \"Now like\", tweet)\n",
    "    tweet = re.sub(r\"seasonfrom\", \"season from\", tweet)\n",
    "    tweet = re.sub(r\"epicente\", \"epicenter\", tweet)\n",
    "    tweet = re.sub(r\"epicenterr\", \"epicenter\", tweet)\n",
    "    tweet = re.sub(r\"sicklife\", \"sick life\", tweet)\n",
    "    tweet = re.sub(r\"yycweather\", \"Calgary Weather\", tweet)\n",
    "    tweet = re.sub(r\"calgarysun\", \"Calgary Sun\", tweet)\n",
    "    tweet = re.sub(r\"approachng\", \"approaching\", tweet)\n",
    "    tweet = re.sub(r\"evng\", \"evening\", tweet)\n",
    "    tweet = re.sub(r\"Sumthng\", \"something\", tweet)\n",
    "    tweet = re.sub(r\"EllenPompeo\", \"Ellen Pompeo\", tweet)\n",
    "    tweet = re.sub(r\"shondarhimes\", \"Shonda Rhimes\", tweet)\n",
    "    tweet = re.sub(r\"ABCNetwork\", \"ABC Network\", tweet)\n",
    "    tweet = re.sub(r\"SushmaSwaraj\", \"Sushma Swaraj\", tweet)\n",
    "    tweet = re.sub(r\"pray4japan\", \"Pray for Japan\", tweet)\n",
    "    tweet = re.sub(r\"hope4japan\", \"Hope for Japan\", tweet)\n",
    "    tweet = re.sub(r\"Illusionimagess\", \"Illusion images\", tweet)\n",
    "    tweet = re.sub(r\"SummerUnderTheStars\", \"Summer Under The Stars\", tweet)\n",
    "    tweet = re.sub(r\"ShallWeDance\", \"Shall We Dance\", tweet)\n",
    "    tweet = re.sub(r\"TCMParty\", \"TCM Party\", tweet)\n",
    "    tweet = re.sub(r\"marijuananews\", \"marijuana news\", tweet)\n",
    "    tweet = re.sub(r\"onbeingwithKristaTippett\", \"on being with Krista Tippett\", tweet)\n",
    "    tweet = re.sub(r\"Beingtweets\", \"Being tweets\", tweet)\n",
    "    tweet = re.sub(r\"newauthors\", \"new authors\", tweet)\n",
    "    tweet = re.sub(r\"remedyyyy\", \"remedy\", tweet)\n",
    "    tweet = re.sub(r\"44PM\", \"44 PM\", tweet)\n",
    "    tweet = re.sub(r\"HeadlinesApp\", \"Headlines App\", tweet)\n",
    "    tweet = re.sub(r\"40PM\", \"40 PM\", tweet)\n",
    "    tweet = re.sub(r\"myswc\", \"Severe Weather Center\", tweet)\n",
    "    tweet = re.sub(r\"ithats\", \"that is\", tweet)\n",
    "    tweet = re.sub(r\"icouldsitinthismomentforever\", \"I could sit in this moment forever\", tweet)\n",
    "    tweet = re.sub(r\"FatLoss\", \"Fat Loss\", tweet)\n",
    "    tweet = re.sub(r\"02PM\", \"02 PM\", tweet)\n",
    "    tweet = re.sub(r\"MetroFmTalk\", \"Metro Fm Talk\", tweet)\n",
    "    tweet = re.sub(r\"Bstrd\", \"bastard\", tweet)\n",
    "    tweet = re.sub(r\"bldy\", \"bloody\", tweet)\n",
    "    tweet = re.sub(r\"MetrofmTalk\", \"Metro Fm Talk\", tweet)\n",
    "    tweet = re.sub(r\"terrorismturn\", \"terrorism turn\", tweet)\n",
    "    tweet = re.sub(r\"BBCNewsAsia\", \"BBC News Asia\", tweet)\n",
    "    tweet = re.sub(r\"BehindTheScenes\", \"Behind The Scenes\", tweet)\n",
    "    tweet = re.sub(r\"GeorgeTakei\", \"George Takei\", tweet)\n",
    "    tweet = re.sub(r\"WomensWeeklyMag\", \"Womens Weekly Magazine\", tweet)\n",
    "    tweet = re.sub(r\"SurvivorsGuidetoEarth\", \"Survivors Guide to Earth\", tweet)\n",
    "    tweet = re.sub(r\"incubusband\", \"incubus band\", tweet)\n",
    "    tweet = re.sub(r\"Babypicturethis\", \"Baby picture this\", tweet)\n",
    "    tweet = re.sub(r\"BombEffects\", \"Bomb Effects\", tweet)\n",
    "    tweet = re.sub(r\"win10\", \"Windows 10\", tweet)\n",
    "    tweet = re.sub(r\"idkidk\", \"I do not know I do not know\", tweet)\n",
    "    tweet = re.sub(r\"TheWalkingDead\", \"The Walking Dead\", tweet)\n",
    "    tweet = re.sub(r\"amyschumer\", \"Amy Schumer\", tweet)\n",
    "    tweet = re.sub(r\"crewlist\", \"crew list\", tweet)\n",
    "    tweet = re.sub(r\"Erdogans\", \"Erdogan\", tweet)\n",
    "    tweet = re.sub(r\"BBCLive\", \"BBC Live\", tweet)\n",
    "    tweet = re.sub(r\"TonyAbbottMHR\", \"Tony Abbott\", tweet)\n",
    "    tweet = re.sub(r\"paulmyerscough\", \"Paul Myerscough\", tweet)\n",
    "    tweet = re.sub(r\"georgegallagher\", \"George Gallagher\", tweet)\n",
    "    tweet = re.sub(r\"JimmieJohnson\", \"Jimmie Johnson\", tweet)\n",
    "    tweet = re.sub(r\"pctool\", \"pc tool\", tweet)\n",
    "    tweet = re.sub(r\"DoingHashtagsRight\", \"Doing Hashtags Right\", tweet)\n",
    "    tweet = re.sub(r\"ThrowbackThursday\", \"Throwback Thursday\", tweet)\n",
    "    tweet = re.sub(r\"SnowBackSunday\", \"Snowback Sunday\", tweet)\n",
    "    tweet = re.sub(r\"LakeEffect\", \"Lake Effect\", tweet)\n",
    "    tweet = re.sub(r\"RTphotographyUK\", \"Richard Thomas Photography UK\", tweet)\n",
    "    tweet = re.sub(r\"BigBang_CBS\", \"Big Bang CBS\", tweet)\n",
    "    tweet = re.sub(r\"writerslife\", \"writers life\", tweet)\n",
    "    tweet = re.sub(r\"NaturalBirth\", \"Natural Birth\", tweet)\n",
    "    tweet = re.sub(r\"UnusualWords\", \"Unusual Words\", tweet)\n",
    "    tweet = re.sub(r\"wizkhalifa\", \"Wiz Khalifa\", tweet)\n",
    "    tweet = re.sub(r\"acreativedc\", \"a creative DC\", tweet)\n",
    "    tweet = re.sub(r\"vscodc\", \"vsco DC\", tweet)\n",
    "    tweet = re.sub(r\"VSCOcam\", \"vsco camera\", tweet)\n",
    "    tweet = re.sub(r\"TheBEACHDC\", \"The beach DC\", tweet)\n",
    "    tweet = re.sub(r\"buildingmuseum\", \"building museum\", tweet)\n",
    "    tweet = re.sub(r\"WorldOil\", \"World Oil\", tweet)\n",
    "    tweet = re.sub(r\"redwedding\", \"red wedding\", tweet)\n",
    "    tweet = re.sub(r\"AmazingRaceCanada\", \"Amazing Race Canada\", tweet)\n",
    "    tweet = re.sub(r\"WakeUpAmerica\", \"Wake Up America\", tweet)\n",
    "    tweet = re.sub(r\"\\\\Allahuakbar\\\\\", \"Allahu Akbar\", tweet)\n",
    "    tweet = re.sub(r\"bleased\", \"blessed\", tweet)\n",
    "    tweet = re.sub(r\"nigeriantribune\", \"Nigerian Tribune\", tweet)\n",
    "    tweet = re.sub(r\"HIDEO_KOJIMA_EN\", \"Hideo Kojima\", tweet)\n",
    "    tweet = re.sub(r\"FusionFestival\", \"Fusion Festival\", tweet)\n",
    "    tweet = re.sub(r\"50Mixed\", \"50 Mixed\", tweet)\n",
    "    tweet = re.sub(r\"NoAgenda\", \"No Agenda\", tweet)\n",
    "    tweet = re.sub(r\"WhiteGenocide\", \"White Genocide\", tweet)\n",
    "    tweet = re.sub(r\"dirtylying\", \"dirty lying\", tweet)\n",
    "    tweet = re.sub(r\"SyrianRefugees\", \"Syrian Refugees\", tweet)\n",
    "    tweet = re.sub(r\"changetheworld\", \"change the world\", tweet)\n",
    "    tweet = re.sub(r\"Ebolacase\", \"Ebola case\", tweet)\n",
    "    tweet = re.sub(r\"mcgtech\", \"mcg technologies\", tweet)\n",
    "    tweet = re.sub(r\"withweapons\", \"with weapons\", tweet)\n",
    "    tweet = re.sub(r\"advancedwarfare\", \"advanced warfare\", tweet)\n",
    "    tweet = re.sub(r\"letsFootball\", \"let us Football\", tweet)\n",
    "    tweet = re.sub(r\"LateNiteMix\", \"late night mix\", tweet)\n",
    "    tweet = re.sub(r\"PhilCollinsFeed\", \"Phil Collins\", tweet)\n",
    "    tweet = re.sub(r\"RudyHavenstein\", \"Rudy Havenstein\", tweet)\n",
    "    tweet = re.sub(r\"22PM\", \"22 PM\", tweet)\n",
    "    tweet = re.sub(r\"54am\", \"54 AM\", tweet)\n",
    "    tweet = re.sub(r\"38am\", \"38 AM\", tweet)\n",
    "    tweet = re.sub(r\"OldFolkExplainStuff\", \"Old Folk Explain Stuff\", tweet)\n",
    "    tweet = re.sub(r\"BlacklivesMatter\", \"Black Lives Matter\", tweet)\n",
    "    tweet = re.sub(r\"InsaneLimits\", \"Insane Limits\", tweet)\n",
    "    tweet = re.sub(r\"youcantsitwithus\", \"you cannot sit with us\", tweet)\n",
    "    tweet = re.sub(r\"2k15\", \"2015\", tweet)\n",
    "    tweet = re.sub(r\"TheIran\", \"Iran\", tweet)\n",
    "    tweet = re.sub(r\"JimmyFallon\", \"Jimmy Fallon\", tweet)\n",
    "    tweet = re.sub(r\"AlbertBrooks\", \"Albert Brooks\", tweet)\n",
    "    tweet = re.sub(r\"defense_news\", \"defense news\", tweet)\n",
    "    tweet = re.sub(r\"nuclearrcSA\", \"Nuclear Risk Control Self Assessment\", tweet)\n",
    "    tweet = re.sub(r\"Auspol\", \"Australia Politics\", tweet)\n",
    "    tweet = re.sub(r\"NuclearPower\", \"Nuclear Power\", tweet)\n",
    "    tweet = re.sub(r\"WhiteTerrorism\", \"White Terrorism\", tweet)\n",
    "    tweet = re.sub(r\"truthfrequencyradio\", \"Truth Frequency Radio\", tweet)\n",
    "    tweet = re.sub(r\"ErasureIsNotEquality\", \"Erasure is not equality\", tweet)\n",
    "    tweet = re.sub(r\"ProBonoNews\", \"Pro Bono News\", tweet)\n",
    "    tweet = re.sub(r\"JakartaPost\", \"Jakarta Post\", tweet)\n",
    "    tweet = re.sub(r\"toopainful\", \"too painful\", tweet)\n",
    "    tweet = re.sub(r\"melindahaunton\", \"Melinda Haunton\", tweet)\n",
    "    tweet = re.sub(r\"NoNukes\", \"No Nukes\", tweet)\n",
    "    tweet = re.sub(r\"curryspcworld\", \"Currys PC World\", tweet)\n",
    "    tweet = re.sub(r\"ineedcake\", \"I need cake\", tweet)\n",
    "    tweet = re.sub(r\"blackforestgateau\", \"black forest gateau\", tweet)\n",
    "    tweet = re.sub(r\"BBCOne\", \"BBC One\", tweet)\n",
    "    tweet = re.sub(r\"AlexxPage\", \"Alex Page\", tweet)\n",
    "    tweet = re.sub(r\"jonathanserrie\", \"Jonathan Serrie\", tweet)\n",
    "    tweet = re.sub(r\"SocialJerkBlog\", \"Social Jerk Blog\", tweet)\n",
    "    tweet = re.sub(r\"ChelseaVPeretti\", \"Chelsea Peretti\", tweet)\n",
    "    tweet = re.sub(r\"irongiant\", \"iron giant\", tweet)\n",
    "    tweet = re.sub(r\"RonFunches\", \"Ron Funches\", tweet)\n",
    "    tweet = re.sub(r\"TimCook\", \"Tim Cook\", tweet)\n",
    "    tweet = re.sub(r\"sebastianstanisaliveandwell\", \"Sebastian Stan is alive and well\", tweet)\n",
    "    tweet = re.sub(r\"Madsummer\", \"Mad summer\", tweet)\n",
    "    tweet = re.sub(r\"NowYouKnow\", \"Now you know\", tweet)\n",
    "    tweet = re.sub(r\"concertphotography\", \"concert photography\", tweet)\n",
    "    tweet = re.sub(r\"TomLandry\", \"Tom Landry\", tweet)\n",
    "    tweet = re.sub(r\"showgirldayoff\", \"show girl day off\", tweet)\n",
    "    tweet = re.sub(r\"Yougslavia\", \"Yugoslavia\", tweet)\n",
    "    tweet = re.sub(r\"QuantumDataInformatics\", \"Quantum Data Informatics\", tweet)\n",
    "    tweet = re.sub(r\"FromTheDesk\", \"From The Desk\", tweet)\n",
    "    tweet = re.sub(r\"TheaterTrial\", \"Theater Trial\", tweet)\n",
    "    tweet = re.sub(r\"CatoInstitute\", \"Cato Institute\", tweet)\n",
    "    tweet = re.sub(r\"EmekaGift\", \"Emeka Gift\", tweet)\n",
    "    tweet = re.sub(r\"LetsBe_Rational\", \"Let us be rational\", tweet)\n",
    "    tweet = re.sub(r\"Cynicalreality\", \"Cynical reality\", tweet)\n",
    "    tweet = re.sub(r\"FredOlsenCruise\", \"Fred Olsen Cruise\", tweet)\n",
    "    tweet = re.sub(r\"NotSorry\", \"not sorry\", tweet)\n",
    "    tweet = re.sub(r\"UseYourWords\", \"use your words\", tweet)\n",
    "    tweet = re.sub(r\"WordoftheDay\", \"word of the day\", tweet)\n",
    "    tweet = re.sub(r\"Dictionarycom\", \"Dictionary.com\", tweet)\n",
    "    tweet = re.sub(r\"TheBrooklynLife\", \"The Brooklyn Life\", tweet)\n",
    "    tweet = re.sub(r\"jokethey\", \"joke they\", tweet)\n",
    "    tweet = re.sub(r\"nflweek1picks\", \"NFL week 1 picks\", tweet)\n",
    "    tweet = re.sub(r\"uiseful\", \"useful\", tweet)\n",
    "    tweet = re.sub(r\"JusticeDotOrg\", \"The American Association for Justice\", tweet)\n",
    "    tweet = re.sub(r\"autoaccidents\", \"auto accidents\", tweet)\n",
    "    tweet = re.sub(r\"SteveGursten\", \"Steve Gursten\", tweet)\n",
    "    tweet = re.sub(r\"MichiganAutoLaw\", \"Michigan Auto Law\", tweet)\n",
    "    tweet = re.sub(r\"birdgang\", \"bird gang\", tweet)\n",
    "    tweet = re.sub(r\"nflnetwork\", \"NFL Network\", tweet)\n",
    "    tweet = re.sub(r\"NYDNSports\", \"NY Daily News Sports\", tweet)\n",
    "    tweet = re.sub(r\"RVacchianoNYDN\", \"Ralph Vacchiano NY Daily News\", tweet)\n",
    "    tweet = re.sub(r\"EdmontonEsks\", \"Edmonton Eskimos\", tweet)\n",
    "    tweet = re.sub(r\"david_brelsford\", \"David Brelsford\", tweet)\n",
    "    tweet = re.sub(r\"TOI_India\", \"The Times of India\", tweet)\n",
    "    tweet = re.sub(r\"hegot\", \"he got\", tweet)\n",
    "    tweet = re.sub(r\"SkinsOn9\", \"Skins on 9\", tweet)\n",
    "    tweet = re.sub(r\"sothathappened\", \"so that happened\", tweet)\n",
    "    tweet = re.sub(r\"LCOutOfDoors\", \"LC Out Of Doors\", tweet)\n",
    "    tweet = re.sub(r\"NationFirst\", \"Nation First\", tweet)\n",
    "    tweet = re.sub(r\"IndiaToday\", \"India Today\", tweet)\n",
    "    tweet = re.sub(r\"HLPS\", \"helps\", tweet)\n",
    "    tweet = re.sub(r\"HOSTAGESTHROSW\", \"hostages throw\", tweet)\n",
    "    tweet = re.sub(r\"SNCTIONS\", \"sanctions\", tweet)\n",
    "    tweet = re.sub(r\"BidTime\", \"Bid Time\", tweet)\n",
    "    tweet = re.sub(r\"crunchysensible\", \"crunchy sensible\", tweet)\n",
    "    tweet = re.sub(r\"RandomActsOfRomance\", \"Random acts of romance\", tweet)\n",
    "    tweet = re.sub(r\"MomentsAtHill\", \"Moments at hill\", tweet)\n",
    "    tweet = re.sub(r\"eatshit\", \"eat shit\", tweet)\n",
    "    tweet = re.sub(r\"liveleakfun\", \"live leak fun\", tweet)\n",
    "    tweet = re.sub(r\"SahelNews\", \"Sahel News\", tweet)\n",
    "    tweet = re.sub(r\"abc7newsbayarea\", \"ABC 7 News Bay Area\", tweet)\n",
    "    tweet = re.sub(r\"facilitiesmanagement\", \"facilities management\", tweet)\n",
    "    tweet = re.sub(r\"facilitydude\", \"facility dude\", tweet)\n",
    "    tweet = re.sub(r\"CampLogistics\", \"Camp logistics\", tweet)\n",
    "    tweet = re.sub(r\"alaskapublic\", \"Alaska public\", tweet)\n",
    "    tweet = re.sub(r\"MarketResearch\", \"Market Research\", tweet)\n",
    "    tweet = re.sub(r\"AccuracyEsports\", \"Accuracy Esports\", tweet)\n",
    "    tweet = re.sub(r\"TheBodyShopAust\", \"The Body Shop Australia\", tweet)\n",
    "    tweet = re.sub(r\"yychail\", \"Calgary hail\", tweet)\n",
    "    tweet = re.sub(r\"yyctraffic\", \"Calgary traffic\", tweet)\n",
    "    tweet = re.sub(r\"eliotschool\", \"eliot school\", tweet)\n",
    "    tweet = re.sub(r\"TheBrokenCity\", \"The Broken City\", tweet)\n",
    "    tweet = re.sub(r\"OldsFireDept\", \"Olds Fire Department\", tweet)\n",
    "    tweet = re.sub(r\"RiverComplex\", \"River Complex\", tweet)\n",
    "    tweet = re.sub(r\"fieldworksmells\", \"field work smells\", tweet)\n",
    "    tweet = re.sub(r\"IranElection\", \"Iran Election\", tweet)\n",
    "    tweet = re.sub(r\"glowng\", \"glowing\", tweet)\n",
    "    tweet = re.sub(r\"kindlng\", \"kindling\", tweet)\n",
    "    tweet = re.sub(r\"riggd\", \"rigged\", tweet)\n",
    "    tweet = re.sub(r\"slownewsday\", \"slow news day\", tweet)\n",
    "    tweet = re.sub(r\"MyanmarFlood\", \"Myanmar Flood\", tweet)\n",
    "    tweet = re.sub(r\"abc7chicago\", \"ABC 7 Chicago\", tweet)\n",
    "    tweet = re.sub(r\"copolitics\", \"Colorado Politics\", tweet)\n",
    "    tweet = re.sub(r\"AdilGhumro\", \"Adil Ghumro\", tweet)\n",
    "    tweet = re.sub(r\"netbots\", \"net bots\", tweet)\n",
    "    tweet = re.sub(r\"byebyeroad\", \"bye bye road\", tweet)\n",
    "    tweet = re.sub(r\"massiveflooding\", \"massive flooding\", tweet)\n",
    "    tweet = re.sub(r\"EndofUS\", \"End of United States\", tweet)\n",
    "    tweet = re.sub(r\"35PM\", \"35 PM\", tweet)\n",
    "    tweet = re.sub(r\"greektheatrela\", \"Greek Theatre Los Angeles\", tweet)\n",
    "    tweet = re.sub(r\"76mins\", \"76 minutes\", tweet)\n",
    "    tweet = re.sub(r\"publicsafetyfirst\", \"public safety first\", tweet)\n",
    "    tweet = re.sub(r\"livesmatter\", \"lives matter\", tweet)\n",
    "    tweet = re.sub(r\"myhometown\", \"my hometown\", tweet)\n",
    "    tweet = re.sub(r\"tankerfire\", \"tanker fire\", tweet)\n",
    "    tweet = re.sub(r\"MEMORIALDAY\", \"memorial day\", tweet)\n",
    "    tweet = re.sub(r\"MEMORIAL_DAY\", \"memorial day\", tweet)\n",
    "    tweet = re.sub(r\"instaxbooty\", \"instagram booty\", tweet)\n",
    "    tweet = re.sub(r\"Jerusalem_Post\", \"Jerusalem Post\", tweet)\n",
    "    tweet = re.sub(r\"WayneRooney_INA\", \"Wayne Rooney\", tweet)\n",
    "    tweet = re.sub(r\"VirtualReality\", \"Virtual Reality\", tweet)\n",
    "    tweet = re.sub(r\"OculusRift\", \"Oculus Rift\", tweet)\n",
    "    tweet = re.sub(r\"OwenJones84\", \"Owen Jones\", tweet)\n",
    "    tweet = re.sub(r\"jeremycorbyn\", \"Jeremy Corbyn\", tweet)\n",
    "    tweet = re.sub(r\"paulrogers002\", \"Paul Rogers\", tweet)\n",
    "    tweet = re.sub(r\"mortalkombatx\", \"Mortal Kombat X\", tweet)\n",
    "    tweet = re.sub(r\"mortalkombat\", \"Mortal Kombat\", tweet)\n",
    "    tweet = re.sub(r\"FilipeCoelho92\", \"Filipe Coelho\", tweet)\n",
    "    tweet = re.sub(r\"OnlyQuakeNews\", \"Only Quake News\", tweet)\n",
    "    tweet = re.sub(r\"kostumes\", \"costumes\", tweet)\n",
    "    tweet = re.sub(r\"YEEESSSS\", \"yes\", tweet)\n",
    "    tweet = re.sub(r\"ToshikazuKatayama\", \"Toshikazu Katayama\", tweet)\n",
    "    tweet = re.sub(r\"IntlDevelopment\", \"Intl Development\", tweet)\n",
    "    tweet = re.sub(r\"ExtremeWeather\", \"Extreme Weather\", tweet)\n",
    "    tweet = re.sub(r\"WereNotGruberVoters\", \"We are not gruber voters\", tweet)\n",
    "    tweet = re.sub(r\"NewsThousands\", \"News Thousands\", tweet)\n",
    "    tweet = re.sub(r\"EdmundAdamus\", \"Edmund Adamus\", tweet)\n",
    "    tweet = re.sub(r\"EyewitnessWV\", \"Eye witness WV\", tweet)\n",
    "    tweet = re.sub(r\"PhiladelphiaMuseu\", \"Philadelphia Museum\", tweet)\n",
    "    tweet = re.sub(r\"DublinComicCon\", \"Dublin Comic Con\", tweet)\n",
    "    tweet = re.sub(r\"NicholasBrendon\", \"Nicholas Brendon\", tweet)\n",
    "    tweet = re.sub(r\"Alltheway80s\", \"All the way 80s\", tweet)\n",
    "    tweet = re.sub(r\"FromTheField\", \"From the field\", tweet)\n",
    "    tweet = re.sub(r\"NorthIowa\", \"North Iowa\", tweet)\n",
    "    tweet = re.sub(r\"WillowFire\", \"Willow Fire\", tweet)\n",
    "    tweet = re.sub(r\"MadRiverComplex\", \"Mad River Complex\", tweet)\n",
    "    tweet = re.sub(r\"feelingmanly\", \"feeling manly\", tweet)\n",
    "    tweet = re.sub(r\"stillnotoverit\", \"still not over it\", tweet)\n",
    "    tweet = re.sub(r\"FortitudeValley\", \"Fortitude Valley\", tweet)\n",
    "    tweet = re.sub(r\"CoastpowerlineTramTr\", \"Coast powerline\", tweet)\n",
    "    tweet = re.sub(r\"ServicesGold\", \"Services Gold\", tweet)\n",
    "    tweet = re.sub(r\"NewsbrokenEmergency\", \"News broken emergency\", tweet)\n",
    "    tweet = re.sub(r\"Evaucation\", \"evacuation\", tweet)\n",
    "    tweet = re.sub(r\"leaveevacuateexitbe\", \"leave evacuate exit be\", tweet)\n",
    "    tweet = re.sub(r\"P_EOPLE\", \"PEOPLE\", tweet)\n",
    "    tweet = re.sub(r\"Tubestrike\", \"tube strike\", tweet)\n",
    "    tweet = re.sub(r\"CLASS_SICK\", \"CLASS SICK\", tweet)\n",
    "    tweet = re.sub(r\"localplumber\", \"local plumber\", tweet)\n",
    "    tweet = re.sub(r\"awesomejobsiri\", \"awesome job siri\", tweet)\n",
    "    tweet = re.sub(r\"PayForItHow\", \"Pay for it how\", tweet)\n",
    "    tweet = re.sub(r\"ThisIsAfrica\", \"This is Africa\", tweet)\n",
    "    tweet = re.sub(r\"crimeairnetwork\", \"crime air network\", tweet)\n",
    "    tweet = re.sub(r\"KimAcheson\", \"Kim Acheson\", tweet)\n",
    "    tweet = re.sub(r\"cityofcalgary\", \"City of Calgary\", tweet)\n",
    "    tweet = re.sub(r\"prosyndicate\", \"pro syndicate\", tweet)\n",
    "    tweet = re.sub(r\"660NEWS\", \"660 NEWS\", tweet)\n",
    "    tweet = re.sub(r\"BusInsMagazine\", \"Business Insurance Magazine\", tweet)\n",
    "    tweet = re.sub(r\"wfocus\", \"focus\", tweet)\n",
    "    tweet = re.sub(r\"ShastaDam\", \"Shasta Dam\", tweet)\n",
    "    tweet = re.sub(r\"go2MarkFranco\", \"Mark Franco\", tweet)\n",
    "    tweet = re.sub(r\"StephGHinojosa\", \"Steph Hinojosa\", tweet)\n",
    "    tweet = re.sub(r\"Nashgrier\", \"Nash Grier\", tweet)\n",
    "    tweet = re.sub(r\"NashNewVideo\", \"Nash new video\", tweet)\n",
    "    tweet = re.sub(r\"IWouldntGetElectedBecause\", \"I would not get elected because\", tweet)\n",
    "    tweet = re.sub(r\"SHGames\", \"Sledgehammer Games\", tweet)\n",
    "    tweet = re.sub(r\"bedhair\", \"bed hair\", tweet)\n",
    "    tweet = re.sub(r\"JoelHeyman\", \"Joel Heyman\", tweet)\n",
    "    tweet = re.sub(r\"viaYouTube\", \"via YouTube\", tweet)\n",
    "           \n",
    "    # URls\n",
    "    tweet = re.sub(r\"https?:\\/\\/t.co\\/[A-Za-z0-9]+\", \"\", tweet)\n",
    "    \n",
    "    # Remove HTML beacon:\n",
    "    tweet = re.sub(r'<.*?>|&([a-z0-9]+|#[0-9]{1,6}|#x[0-9a-f]{1,6});', '', tweet)\n",
    "        \n",
    "    # Words with punctuations and special characters\n",
    "    punctuations = '@#!?+&*[]-%.:/();$=><|{}^' + \"'`\"\n",
    "    for p in punctuations:\n",
    "        tweet = tweet.replace(p, '')\n",
    "        \n",
    "    # ... and ..\n",
    "    tweet = tweet.replace('...', ' ... ')\n",
    "    if '...' not in tweet:\n",
    "        tweet = tweet.replace('..', ' ... ')      \n",
    "        \n",
    "    # Acronyms\n",
    "    tweet = re.sub(r\"MH370\", \"Malaysia Airlines Flight 370\", tweet)\n",
    "    tweet = re.sub(r\"mÌ¼sica\", \"music\", tweet)\n",
    "    tweet = re.sub(r\"okwx\", \"Oklahoma City Weather\", tweet)\n",
    "    tweet = re.sub(r\"arwx\", \"Arkansas Weather\", tweet)    \n",
    "    tweet = re.sub(r\"gawx\", \"Georgia Weather\", tweet)  \n",
    "    tweet = re.sub(r\"scwx\", \"South Carolina Weather\", tweet)  \n",
    "    tweet = re.sub(r\"cawx\", \"California Weather\", tweet)\n",
    "    tweet = re.sub(r\"tnwx\", \"Tennessee Weather\", tweet)\n",
    "    tweet = re.sub(r\"azwx\", \"Arizona Weather\", tweet)  \n",
    "    tweet = re.sub(r\"alwx\", \"Alabama Weather\", tweet)\n",
    "    tweet = re.sub(r\"wordpressdotcom\", \"wordpress\", tweet)    \n",
    "    tweet = re.sub(r\"usNWSgov\", \"United States National Weather Service\", tweet)\n",
    "    tweet = re.sub(r\"Suruc\", \"Sanliurfa\", tweet)   \n",
    "    \n",
    "    # Grouping same words without embeddings\n",
    "    tweet = re.sub(r\"Bestnaijamade\", \"bestnaijamade\", tweet)\n",
    "    tweet = re.sub(r\"SOUDELOR\", \"Soudelor\", tweet)\n",
    "    \n",
    "    #Removing non-printable characters:\n",
    "    tweet = ''.join([word for word in tweet if word in string.printable])\n",
    "    \n",
    "    return tweet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c5ba505d-31f8-4290-a32f-968d2d19b3c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extra_cleaning(tweet):\n",
    "    tweet = re.sub(r\"hwy\", \"highway\", tweet)\n",
    "    tweet = re.sub(r\" st \", \" saint \", tweet)\n",
    "    tweet = re.sub(r\" mar \", \" march \", tweet)\n",
    "    tweet = re.sub(r\"accidentwho\", \"accident who\", tweet)\n",
    "    tweet = re.sub(r\"stlouis\", \"saint louis\", tweet)\n",
    "    tweet = re.sub(r\"mins\", \"minutes\", tweet)\n",
    "    tweet = re.sub(r\"measuresarrestpastornganga\", \"measures arrest pastor ganga\", tweet)\n",
    "    tweet = re.sub(r\"edm\", \"electronic dance music\", tweet)\n",
    "    tweet = re.sub(r\"growingupspoiled\", \"growing up spoiled\", tweet)\n",
    "    tweet = re.sub(r\"esquireattire\", \"esquire attire\", tweet)\n",
    "    tweet = re.sub(r\"watchthevideo\", \"watch the video\", tweet)\n",
    "    tweet = re.sub(r\"airplane29072015\", \"airplane 29072015\", tweet)\n",
    "    tweet = re.sub(r\" esp \", \" especially \", tweet)\n",
    "    tweet = re.sub(r\"justsaying\", \"just saying\", tweet)\n",
    "    tweet = re.sub(r\"randomthought\", \"random thought\", tweet)\n",
    "    tweet = re.sub(r\"rejectdcartoons\", \"rejected cartoons\", tweet)\n",
    "    tweet = re.sub(r\" ems \", \" emergency medical services \", tweet)\n",
    "    tweet = re.sub(r\"worldnews\", \"world news\", tweet)\n",
    "    tweet = re.sub(r\"floydmayweather\", \"floyd mayweather\", tweet)\n",
    "    tweet = re.sub(r\"butthe\", \"but the\", tweet)\n",
    "    tweet = re.sub(r\"withnukes\", \"with nukes\", tweet)\n",
    "    tweet = re.sub(r\"philipduncan\", \"philip duncan\", tweet)\n",
    "    tweet = re.sub(r\"breakfastone\", \"breakfast one\", tweet)\n",
    "    tweet = re.sub(r\"withfries\", \"with fries\", tweet)\n",
    "    tweet = re.sub(r\"happyhour\", \"happy hour\", tweet)\n",
    "    tweet = re.sub(r\"usa\", \"united states of america\", tweet)\n",
    "    tweet = re.sub(r\"ritzyjewels\", \"ritzy jewels\", tweet)\n",
    "    tweet = re.sub(r\"evildead\", \"evil dead\", tweet)\n",
    "    tweet = re.sub(r\"quarterstaff\", \"quarter staff\", tweet)\n",
    "    tweet = re.sub(r\"kimkardashian\", \"kim kardashian\", tweet)\n",
    "    tweet = re.sub(r\"theellenshow\", \"the ellen show\", tweet)\n",
    "    tweet = re.sub(r\"signatureschange\", \"signatures change\", tweet)\n",
    "    tweet = re.sub(r\"withannihilation\", \"with annihilation\", tweet)\n",
    "    tweet = re.sub(r\"ppor\", \"poor\", tweet)\n",
    "    tweet = re.sub(r\"sciencefiction\", \"science fiction\", tweet)\n",
    "    tweet = re.sub(r\"internetradio\", \"internet radio\", tweet)\n",
    "    tweet = re.sub(r\"primalkitchen\", \"primal kitchen\", tweet)\n",
    "    tweet = re.sub(r\" gf \", \" girlfriend \", tweet)\n",
    "    tweet = re.sub(r\"warmbodies\", \"warm bodies\", tweet)\n",
    "    tweet = re.sub(r\"ourmothermary\", \"our mother mary\", tweet)\n",
    "    tweet = re.sub(r\"geekapocalypse\", \"geek apocalypse\", tweet)\n",
    "    tweet = re.sub(r\"bryansinger\", \"bryan singer\", tweet)\n",
    "    tweet = re.sub(r\"liveaction\", \"live action\", tweet)\n",
    "    tweet = re.sub(r\"doublecups\", \"double cups\", tweet)\n",
    "    tweet = re.sub(r\"katiekatcubs\", \"katie kat cubs\", tweet)\n",
    "    tweet = re.sub(r\"truelove\", \"true love\", tweet)\n",
    "    tweet = re.sub(r\"wifekids\", \"wife kids\", tweet)\n",
    "    tweet = re.sub(r\"eonlinechat\", \"online chat\", tweet)\n",
    "    tweet = re.sub(r\"brucewillis\", \"bruce willis\", tweet)\n",
    "    tweet = re.sub(r\"preseasonworkouts\", \"preseason workouts\", tweet)\n",
    "    tweet = re.sub(r\" pd \", \" police department \", tweet)\n",
    "    tweet = re.sub(r\"thereal\", \"the real\", tweet)\n",
    "    tweet = re.sub(r\"22beyonce\", \"beyonce\", tweet)\n",
    "    tweet = re.sub(r\"17beyonce\", \"beyonce\", tweet)\n",
    "    tweet = re.sub(r\"fanarmyfaceoff\", \"fan army face off\", tweet)\n",
    "    tweet = re.sub(r\"7beyonce\", \"beyonce\", tweet)\n",
    "    tweet = re.sub(r\"6beyonce\", \"beyonce\", tweet)\n",
    "    tweet = re.sub(r\"wwi\", \"world war one\", tweet)\n",
    "    tweet = re.sub(r\"ww1\", \"world war one\", tweet)\n",
    "    tweet = re.sub(r\"wwii\", \"world war two\", tweet)\n",
    "    tweet = re.sub(r\"ww2\", \"world war two\", tweet)\n",
    "    tweet = re.sub(r\"chicagoarea\", \"chicago area\", tweet)\n",
    "    tweet = re.sub(r\"lgbt\", \"lesbian gay bisexual transgender\", tweet)\n",
    "    tweet = re.sub(r\"countynews\", \"county news\", tweet)\n",
    "    tweet = re.sub(r\"latimes\", \"los angeles times\", tweet)\n",
    "    tweet = re.sub(r\" la \", \" los angeles \", tweet)\n",
    "    tweet = re.sub(r\" calif \", \" california \", tweet)\n",
    "    tweet = re.sub(r\"localarsonist\", \"local arsonist\", tweet)\n",
    "    tweet = re.sub(r\"uniteblue\", \"unite blue\", tweet)\n",
    "    tweet = re.sub(r\"govegan\", \"go vegan\", tweet)\n",
    "    tweet = re.sub(r\"2minutemix\", \"two minute mix\", tweet)\n",
    "    tweet = re.sub(r\"arsonistmusic\", \"arsonist music\", tweet)\n",
    "    tweet = re.sub(r\"hotboy\", \"hot boy\", tweet)\n",
    "    tweet = re.sub(r\"sanfrancisco\", \"san francisco\", tweet)\n",
    "    tweet = re.sub(r\"newyork\", \"new york\", tweet)\n",
    "    tweet = re.sub(r\"slimebeast\", \"slime beast\", tweet)\n",
    "    tweet = re.sub(r\"bestcomedyvine\", \"best comedy vine\", tweet)\n",
    "    tweet = re.sub(r\"nativehuman\", \"native human\", tweet)\n",
    "    tweet = re.sub(r\"myreligion\", \"my religion\", tweet)\n",
    "    tweet = re.sub(r\"liveleak\", \"live leak\", tweet)\n",
    "    tweet = re.sub(r\"acebreakingnews\", \"ace breaking news\", tweet)\n",
    "    tweet = re.sub(r\"breakingnews\", \"breaking news\", tweet)\n",
    "    tweet = re.sub(r\"allthenews\", \"all the news\", tweet)\n",
    "    tweet = re.sub(r\"livemint\", \"live mint\", tweet)\n",
    "    tweet = re.sub(r\" us \", \" united states \", tweet)\n",
    "    tweet = re.sub(r\" shud \", \" should \", tweet)\n",
    "    tweet = re.sub(r\"latinoand\", \"latino and\", tweet)\n",
    "    tweet = re.sub(r\"daytonarea\", \"dayton area\", tweet)\n",
    "    tweet = re.sub(r\"justinbieber\", \"justin bieber\", tweet)\n",
    "    tweet = re.sub(r\"harrystyles\", \"harry styles\", tweet)\n",
    "    tweet = re.sub(r\"westminister\", \"west minister\", tweet)\n",
    "    tweet = re.sub(r\"eyewitness\", \"eye witness\", tweet)\n",
    "    tweet = re.sub(r\"hazarddangerous\", \"hazard dangerous\", tweet)\n",
    "    tweet = re.sub(r\"labourleadership\", \"labor leadership\", tweet)\n",
    "    tweet = re.sub(r\" uk \", \" united kingdom \", tweet)\n",
    "    tweet = re.sub(r\"worldnetdailyhomosexuality\", \"world net daily homosexuality\", tweet)\n",
    "    tweet = re.sub(r\"worldnetdaily\", \"world net daily\", tweet)\n",
    "    tweet = re.sub(r\"thisishavehope\", \"this is have hope\", tweet)\n",
    "    tweet = re.sub(r\"yonews\", \"yo news\", tweet)\n",
    "    tweet = re.sub(r\"nowplaying\", \"now playing\", tweet)\n",
    "    tweet = re.sub(r\"supernovalester\", \"supernova lester\", tweet)\n",
    "    tweet = re.sub(r\"abandonedpics\", \"abandoned pictures\", tweet)\n",
    "    tweet = re.sub(r\"blackcats\", \"black cats\", tweet)\n",
    "    tweet = re.sub(r\"chemicalweapons\", \"chemical weapons\", tweet)\n",
    "    tweet = re.sub(r\"ineedexposure\", \"i need exposure\", tweet)\n",
    "    tweet = re.sub(r\"uswarcrimes\", \"united states war crimes\", tweet)\n",
    "    tweet = re.sub(r\" pic \", \" pictures \", tweet)\n",
    "    tweet = re.sub(r\"explodingkittens\", \"exploding kittens\", tweet)\n",
    "    tweet = re.sub(r\"explosivespacked\", \"explosive packed\", tweet)\n",
    "    tweet = re.sub(r\"fatherofthree\", \"father of three\", tweet)\n",
    "    tweet = re.sub(r\"stormchase\", \"storm chase\", tweet)\n",
    "    \n",
    "    return tweet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "da383542-59a1-483a-b17a-ff9f48539e72",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Overall Cleaning Function to Run:\n",
    "def clean_tweet(text):\n",
    "    text = clean(text)\n",
    "    text = extra_cleaning(text)\n",
    "    text = text.lower()\n",
    "    text = replace_abbrev(text)  \n",
    "    text = remove_emoji(text)\n",
    "    text = remove_punct(text)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3d47495c-76be-47f4-8eae-757766f2a327",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cleaning Train and Test Data:\n",
    "df_train['text'] = df_train['text'].apply(clean_tweet)\n",
    "df_test['text'] = df_test['text'].apply(clean_tweet)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98eba97c-fcfc-484d-ba9f-56db75477835",
   "metadata": {},
   "source": [
    "#### Filling Null Values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d365e1b4-0243-4f62-8e4e-0e16ff057e34",
   "metadata": {},
   "outputs": [],
   "source": [
    "for df in [df_train, df_test]:\n",
    "    for col in ['keyword', 'location', 'text']:\n",
    "        df[col] = df[col].fillna(f'no_{col}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edd6ed62-0364-49a5-bc55-866fea90c1c8",
   "metadata": {},
   "source": [
    "#### Removing Excess Whitespace:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "422883d4-96a6-4c5a-af79-3861bd2ae89f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_whitespace(tweet):\n",
    "    return \" \".join(tweet.split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "ec877f0c-ac5b-4219-aba1-82978b2b3c9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cleaning Train and Test Data:\n",
    "df_train['text'] = df_train['text'].apply(remove_whitespace)\n",
    "df_test['text'] = df_test['text'].apply(remove_whitespace)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "795d6bf4-662e-4dad-85a1-bd30caca9c46",
   "metadata": {},
   "source": [
    "#### Dealing with Mislabeled Samples:\n",
    "As we know, the dataset has duplicates, but some of these duplicates have the opposite label. We relabel these tweets because they affect the training score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "ea28ede2-22c6-42aa-a85e-ffca31447fa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# thestr = ''\n",
    "# oneList = ['2pcs 18w cree led work light offroad lamp car truck boat mining 4wd flood beam full rea',\n",
    "#           'earthquake drill', \n",
    "#            'potus strategic patience is a strategy for genocide refugees idp internally displaced people horror and so on', \n",
    "#            'how is it one careless match can start a forest fire but it takes a whole box to start a campfire', \n",
    "#            'ashes 2015 australias collapse at trent bridge among worst in history england bundled out australia for 60', \n",
    "#            'wowo 12000 nigerian refugees repatriated from cameroon', \n",
    "#            'us national park services tonto national forest stop the annihilation of the salt river wild horse via change', \n",
    "#            'world annihilation vs self transformation aliens attack to exterminate humans', \n",
    "#            'hot c130 specially modified to land in a stadium and rescue hostages in iran in 1980 prebreak best', \n",
    "#            'caution breathing may be hazardous to your health', \n",
    "#            'kosciusko police investigating pedestrian fatality hit by a train thursday', \n",
    "#            'who is bringing the tornadoes and floods who is bringing the climate change god is after america he is plaguing her farrakhan quote', \n",
    "#            'angry woman openly accuses nema of stealing relief materials meant for internally displaced people an angry internally displaced wom', \n",
    "#            'food scare offers to go nestle india slips into loss after magginoodle ban unsafe and hazardous for human consumption']\n",
    "# for row in df_mislabeled.index.tolist():\n",
    "#     if row in oneList:\n",
    "#         thestr = thestr + 'df_train.loc[df_train[\"text\"] == \\'' + row + '\\', \"target_relabeled\"] = 1\\n'\n",
    "#     else:\n",
    "#         thestr = thestr + 'df_train.loc[df_train[\"text\"] == \\'' + row + '\\', \"target_relabeled\"] = 0\\n'\n",
    "# print(thestr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "e13fcd2c-3d07-49b7-8aea-01ac89256c03",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# dftemp = pd.DataFrame()\n",
    "# for row in df_mislabeled.index.tolist():\n",
    "#     dftemp = dftemp.append(df_train.loc[df_train['text'] == row])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "6526f466-3488-40bf-b6cd-61b156aca885",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['enugu government to demolish illegal structures at international conference centre',\n",
       " 'reddit is new content policy goes into effect many horrible subreddits banned or quarantined',\n",
       " 'like for the music video i want some real action shit like burning buildings and police chases not some weak ben winston shit',\n",
       " 'sassy city girl country hunk stranded in smoky mountain snowstorm aoms i book love book boost',\n",
       " '2pcs 18w cree led work light offroad lamp car truck boat mining 4wd flood beam full rea',\n",
       " 'the dress memes have officially exploded on the internet',\n",
       " 'pandemonium in aba as woman delivers baby without face photos',\n",
       " 'earthquake drill',\n",
       " 'to fight bioterrorism sir',\n",
       " 'star wars power of the jedi collection 1 battle droid hasbro full read by ebay',\n",
       " 'that horrible sinking feeling when you have been at home on your phone for a while and you realise its been on 3g this whole time',\n",
       " 'fire hazard associated with installation of noncompliant external cladding on by wwwcbp lawyers',\n",
       " 'the prophet peace be upon him said save yourself from hellfire even if it is by giving half a date in charity',\n",
       " 'cindy noonancindy noonanheartbreak in baltimore rioting yahistorical underground railraod',\n",
       " 'detonate feat mop by apollo brown',\n",
       " 'hollywood movie about trapped miners released in chile the 33 hollywood movie about trapped miners starring',\n",
       " 'hollywood movie about trapped miners released in chile',\n",
       " 'potus strategic patience is a strategy for genocide refugees idp internally displaced people horror and so on',\n",
       " 'detonation fashionable mountaineering electronic watch waterresistant couples leisure tab',\n",
       " 'a look at state actions a year after fergusons upheaval',\n",
       " 'truth news british broadcasting corporation cnn islam truth god isis terrorism quran lies',\n",
       " 'hellfire is surrounded by desires so be careful and dont let your desires control you afterlife',\n",
       " 'texas seeks comment on rules for changes to windstorm insurer',\n",
       " 'allah describes piling up wealth thinking it would last forever as the description of the people of hellfire in surah humaza reflect',\n",
       " '360wisenews chinas stock market crash are there gems in the rubble',\n",
       " 'hellfire we dont even want to think about it or mention it so let united states not do anything that leads to it islam',\n",
       " 'i liked a youtube video from justin stuart gun range mayhem',\n",
       " 'how is it one careless match can start a forest fire but it takes a whole box to start a campfire',\n",
       " 'ashes 2015 australias collapse at trent bridge among worst in history england bundled out australia for 60',\n",
       " 'wowo 12000 nigerian refugees repatriated from cameroon',\n",
       " 'trafford centre film fans angry after odeon cinema evacuated following false fire alarm',\n",
       " 'fatality',\n",
       " 'us national park services tonto national forest stop the annihilation of the salt river wild horse via change',\n",
       " 'remove the and linkury browser hijacker',\n",
       " 'the way you move is like a full on rainstorm and i am a house of cards',\n",
       " 'fedex no longer to transport bioterror germs in wake of anthrax lab mishaps',\n",
       " 'world war ii book lightning joe an autobiography by general j lawton collins',\n",
       " 'drunk meals 101 what to cook when you are totally obliterated',\n",
       " 'fedex no longer to transport bioterror germs in wake of anthrax lab mishaps via united states of americatoday',\n",
       " 'world fedex no longer to transport bioterror germs in wake of anthrax lab mishaps',\n",
       " 'owner of chicago area gay bar admits to arson scheme lesbian gay bisexual transgender',\n",
       " 'hot reddit is new content policy goes into effect many horrible subreddits banned or quarantined prebreak best',\n",
       " 'world annihilation vs self transformation aliens attack to exterminate humans',\n",
       " 'hot funtenna hijacking computers to send data as sound waves black hat 2015 prebreak best',\n",
       " 'hot c130 specially modified to land in a stadium and rescue hostages in iran in 1980 prebreak best',\n",
       " 'clearedincident with injuryi495 inner loop exit 31 md 97georgia ave silver spring',\n",
       " 'reddit will now quarantine offensive content',\n",
       " 'reddit updates content policy promises to quarantine extremely offensive communities',\n",
       " 'caution breathing may be hazardous to your health',\n",
       " 'he came to a land which was engulfed in tribal war and turned it into a land of peace that is madinah prophet muhammad islam',\n",
       " 'choking hazard prompts recall of kraft cheese singles',\n",
       " 'kosciusko police investigating pedestrian fatality hit by a train thursday',\n",
       " 'mmmmmm i am burning i am burning buildings i am building oooooohhhh oooh ooh',\n",
       " 'spot flood combo 53 inch 300w curved cree led work light bar 4x4 offroad fog lamp full re',\n",
       " 'swansea plot hijack transfer move for southampton target virgil van dijk',\n",
       " 'twia board approves 5 percent rate hike the texas windstorm insurance association twia board of directors v',\n",
       " 'petition heartless owner that whipped horse until it collapsed is told he can keep his animal act now',\n",
       " 'in islam saving a person is equal in reward to saving all humans islam is the opposite of terrorism',\n",
       " 'heres how media in pakistan covered the capture of terrorist mohammed naved',\n",
       " 'who is bringing the tornadoes and floods who is bringing the climate change god is after america he is plaguing her farrakhan quote',\n",
       " 'retweet not explained the only known image of infamous hijacker db cooper',\n",
       " 'survival kit whistle fire starter wire saw cree torch emergency blanket s knife full re',\n",
       " 'accionempresa chinas stock market crash this summer has sparked interest from bargain hunt gerenciatodos',\n",
       " 'angry woman openly accuses nema of stealing relief materials meant for internally displaced people an angry internally displaced wom',\n",
       " 'new ladies shoulder tote handbag faux leather hobo purse cross body bag womens',\n",
       " 'bayelsa poll tension in bayelsa as patience jonathan plans to hijack apc pdp plans by former first lady and',\n",
       " 'watch sarah palin obliterate planned parenthood for targeting minority women bb4sp',\n",
       " 'i pledge allegiance to the pope and the burning buildings of epic city',\n",
       " 'why are you deluged with low selfimage take the quiz',\n",
       " 'governor weighs parole for california school bus hijacker',\n",
       " 'do you feel like you are sinking in low selfimage take the quiz',\n",
       " 'food scare offers to go nestle india slips into loss after magginoodle ban unsafe and hazardous for human consumption']"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_mislabeled = df_train.groupby(['text']).nunique().sort_values(by='target', ascending=False)\n",
    "df_mislabeled = df_mislabeled[df_mislabeled['target'] > 1]['target']\n",
    "df_mislabeled.index.tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c340e36d-f29c-4fe1-b987-e4945a331c91",
   "metadata": {},
   "source": [
    "NEED TO ADJUST TEXT BELOW BASED ON CELL ABOVE!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "3c1bd5e0-3325-454b-9a8b-f41dd33daae3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['target_relabeled'] = df_train['target'].copy()\n",
    "\n",
    "df_train.loc[df_train[\"text\"] == 'enugu government to demolish illegal structures at international conference centre', \"target_relabeled\"] = 0\n",
    "df_train.loc[df_train[\"text\"] == 'reddit is new content policy goes into effect many horrible subreddits banned or quarantined', \"target_relabeled\"] = 0\n",
    "df_train.loc[df_train[\"text\"] == 'like for the music video i want some real action shit like burning buildings and police chases not some weak ben winston shit', \"target_relabeled\"] = 0\n",
    "df_train.loc[df_train[\"text\"] == 'sassy city girl country hunk stranded in smoky mountain snowstorm aoms i book love book boost', \"target_relabeled\"] = 0\n",
    "df_train.loc[df_train[\"text\"] == '2pcs 18w cree led work light offroad lamp car truck boat mining 4wd flood beam full rea', \"target_relabeled\"] = 1\n",
    "df_train.loc[df_train[\"text\"] == 'the dress memes have officially exploded on the internet', \"target_relabeled\"] = 0\n",
    "df_train.loc[df_train[\"text\"] == 'pandemonium in aba as woman delivers baby without face photos', \"target_relabeled\"] = 0\n",
    "df_train.loc[df_train[\"text\"] == 'earthquake drill', \"target_relabeled\"] = 1\n",
    "df_train.loc[df_train[\"text\"] == 'to fight bioterrorism sir', \"target_relabeled\"] = 0\n",
    "df_train.loc[df_train[\"text\"] == 'star wars power of the jedi collection 1 battle droid hasbro full read by ebay', \"target_relabeled\"] = 0\n",
    "df_train.loc[df_train[\"text\"] == 'that horrible sinking feeling when you have been at home on your phone for a while and you realise its been on 3g this whole time', \"target_relabeled\"] = 0\n",
    "df_train.loc[df_train[\"text\"] == 'fire hazard associated with installation of noncompliant external cladding on by wwwcbp lawyers', \"target_relabeled\"] = 0\n",
    "df_train.loc[df_train[\"text\"] == 'the prophet peace be upon him said save yourself from hellfire even if it is by giving half a date in charity', \"target_relabeled\"] = 0\n",
    "df_train.loc[df_train[\"text\"] == 'cindy noonancindy noonanheartbreak in baltimore rioting yahistorical underground railraod', \"target_relabeled\"] = 0\n",
    "df_train.loc[df_train[\"text\"] == 'detonate feat mop by apollo brown', \"target_relabeled\"] = 0\n",
    "df_train.loc[df_train[\"text\"] == 'hollywood movie about trapped miners released in chile the 33 hollywood movie about trapped miners starring', \"target_relabeled\"] = 0\n",
    "df_train.loc[df_train[\"text\"] == 'hollywood movie about trapped miners released in chile', \"target_relabeled\"] = 0\n",
    "df_train.loc[df_train[\"text\"] == 'potus strategic patience is a strategy for genocide refugees idp internally displaced people horror and so on', \"target_relabeled\"] = 1\n",
    "df_train.loc[df_train[\"text\"] == 'detonation fashionable mountaineering electronic watch waterresistant couples leisure tab', \"target_relabeled\"] = 0\n",
    "df_train.loc[df_train[\"text\"] == 'a look at state actions a year after fergusons upheaval', \"target_relabeled\"] = 0\n",
    "df_train.loc[df_train[\"text\"] == 'truth news british broadcasting corporation cnn islam truth god isis terrorism quran lies', \"target_relabeled\"] = 0\n",
    "df_train.loc[df_train[\"text\"] == 'hellfire is surrounded by desires so be careful and dont let your desires control you afterlife', \"target_relabeled\"] = 0\n",
    "df_train.loc[df_train[\"text\"] == 'texas seeks comment on rules for changes to windstorm insurer', \"target_relabeled\"] = 0\n",
    "df_train.loc[df_train[\"text\"] == 'allah describes piling up wealth thinking it would last forever as the description of the people of hellfire in surah humaza reflect', \"target_relabeled\"] = 0\n",
    "df_train.loc[df_train[\"text\"] == '360wisenews chinas stock market crash are there gems in the rubble', \"target_relabeled\"] = 0\n",
    "df_train.loc[df_train[\"text\"] == 'hellfire we dont even want to think about it or mention it so let united states not do anything that leads to it islam', \"target_relabeled\"] = 0\n",
    "df_train.loc[df_train[\"text\"] == 'i liked a youtube video from justin stuart gun range mayhem', \"target_relabeled\"] = 0\n",
    "df_train.loc[df_train[\"text\"] == 'how is it one careless match can start a forest fire but it takes a whole box to start a campfire', \"target_relabeled\"] = 1\n",
    "df_train.loc[df_train[\"text\"] == 'ashes 2015 australias collapse at trent bridge among worst in history england bundled out australia for 60', \"target_relabeled\"] = 1\n",
    "df_train.loc[df_train[\"text\"] == 'wowo 12000 nigerian refugees repatriated from cameroon', \"target_relabeled\"] = 1\n",
    "df_train.loc[df_train[\"text\"] == 'trafford centre film fans angry after odeon cinema evacuated following false fire alarm', \"target_relabeled\"] = 0\n",
    "df_train.loc[df_train[\"text\"] == 'fatality', \"target_relabeled\"] = 0\n",
    "df_train.loc[df_train[\"text\"] == 'us national park services tonto national forest stop the annihilation of the salt river wild horse via change', \"target_relabeled\"] = 1\n",
    "df_train.loc[df_train[\"text\"] == 'remove the and linkury browser hijacker', \"target_relabeled\"] = 0\n",
    "df_train.loc[df_train[\"text\"] == 'the way you move is like a full on rainstorm and i am a house of cards', \"target_relabeled\"] = 0\n",
    "df_train.loc[df_train[\"text\"] == 'fedex no longer to transport bioterror germs in wake of anthrax lab mishaps', \"target_relabeled\"] = 0\n",
    "df_train.loc[df_train[\"text\"] == 'world war ii book lightning joe an autobiography by general j lawton collins', \"target_relabeled\"] = 0\n",
    "df_train.loc[df_train[\"text\"] == 'drunk meals 101 what to cook when you are totally obliterated', \"target_relabeled\"] = 0\n",
    "df_train.loc[df_train[\"text\"] == 'fedex no longer to transport bioterror germs in wake of anthrax lab mishaps via united states of americatoday', \"target_relabeled\"] = 0\n",
    "df_train.loc[df_train[\"text\"] == 'world fedex no longer to transport bioterror germs in wake of anthrax lab mishaps', \"target_relabeled\"] = 0\n",
    "df_train.loc[df_train[\"text\"] == 'owner of chicago area gay bar admits to arson scheme lesbian gay bisexual transgender', \"target_relabeled\"] = 0\n",
    "df_train.loc[df_train[\"text\"] == 'hot reddit is new content policy goes into effect many horrible subreddits banned or quarantined prebreak best', \"target_relabeled\"] = 0\n",
    "df_train.loc[df_train[\"text\"] == 'world annihilation vs self transformation aliens attack to exterminate humans', \"target_relabeled\"] = 1\n",
    "df_train.loc[df_train[\"text\"] == 'hot funtenna hijacking computers to send data as sound waves black hat 2015 prebreak best', \"target_relabeled\"] = 0\n",
    "df_train.loc[df_train[\"text\"] == 'hot c130 specially modified to land in a stadium and rescue hostages in iran in 1980 prebreak best', \"target_relabeled\"] = 1\n",
    "df_train.loc[df_train[\"text\"] == 'clearedincident with injuryi495 inner loop exit 31 md 97georgia ave silver spring', \"target_relabeled\"] = 0\n",
    "df_train.loc[df_train[\"text\"] == 'reddit will now quarantine offensive content', \"target_relabeled\"] = 0\n",
    "df_train.loc[df_train[\"text\"] == 'reddit updates content policy promises to quarantine extremely offensive communities', \"target_relabeled\"] = 0\n",
    "df_train.loc[df_train[\"text\"] == 'caution breathing may be hazardous to your health', \"target_relabeled\"] = 1\n",
    "df_train.loc[df_train[\"text\"] == 'he came to a land which was engulfed in tribal war and turned it into a land of peace that is madinah prophet muhammad islam', \"target_relabeled\"] = 0\n",
    "df_train.loc[df_train[\"text\"] == 'choking hazard prompts recall of kraft cheese singles', \"target_relabeled\"] = 0\n",
    "df_train.loc[df_train[\"text\"] == 'kosciusko police investigating pedestrian fatality hit by a train thursday', \"target_relabeled\"] = 1\n",
    "df_train.loc[df_train[\"text\"] == 'mmmmmm i am burning i am burning buildings i am building oooooohhhh oooh ooh', \"target_relabeled\"] = 0\n",
    "df_train.loc[df_train[\"text\"] == 'spot flood combo 53 inch 300w curved cree led work light bar 4x4 offroad fog lamp full re', \"target_relabeled\"] = 0\n",
    "df_train.loc[df_train[\"text\"] == 'swansea plot hijack transfer move for southampton target virgil van dijk', \"target_relabeled\"] = 0\n",
    "df_train.loc[df_train[\"text\"] == 'twia board approves 5 percent rate hike the texas windstorm insurance association twia board of directors v', \"target_relabeled\"] = 0\n",
    "df_train.loc[df_train[\"text\"] == 'petition heartless owner that whipped horse until it collapsed is told he can keep his animal act now', \"target_relabeled\"] = 0\n",
    "df_train.loc[df_train[\"text\"] == 'in islam saving a person is equal in reward to saving all humans islam is the opposite of terrorism', \"target_relabeled\"] = 0\n",
    "df_train.loc[df_train[\"text\"] == 'heres how media in pakistan covered the capture of terrorist mohammed naved', \"target_relabeled\"] = 0\n",
    "df_train.loc[df_train[\"text\"] == 'who is bringing the tornadoes and floods who is bringing the climate change god is after america he is plaguing her farrakhan quote', \"target_relabeled\"] = 1\n",
    "df_train.loc[df_train[\"text\"] == 'retweet not explained the only known image of infamous hijacker db cooper', \"target_relabeled\"] = 0\n",
    "df_train.loc[df_train[\"text\"] == 'survival kit whistle fire starter wire saw cree torch emergency blanket s knife full re', \"target_relabeled\"] = 0\n",
    "df_train.loc[df_train[\"text\"] == 'accionempresa chinas stock market crash this summer has sparked interest from bargain hunt gerenciatodos', \"target_relabeled\"] = 0\n",
    "df_train.loc[df_train[\"text\"] == 'angry woman openly accuses nema of stealing relief materials meant for internally displaced people an angry internally displaced wom', \"target_relabeled\"] = 1\n",
    "df_train.loc[df_train[\"text\"] == 'new ladies shoulder tote handbag faux leather hobo purse cross body bag womens', \"target_relabeled\"] = 0\n",
    "df_train.loc[df_train[\"text\"] == 'bayelsa poll tension in bayelsa as patience jonathan plans to hijack apc pdp plans by former first lady and', \"target_relabeled\"] = 0\n",
    "df_train.loc[df_train[\"text\"] == 'watch sarah palin obliterate planned parenthood for targeting minority women bb4sp', \"target_relabeled\"] = 0\n",
    "df_train.loc[df_train[\"text\"] == 'i pledge allegiance to the pope and the burning buildings of epic city', \"target_relabeled\"] = 0\n",
    "df_train.loc[df_train[\"text\"] == 'why are you deluged with low selfimage take the quiz', \"target_relabeled\"] = 0\n",
    "df_train.loc[df_train[\"text\"] == 'governor weighs parole for california school bus hijacker', \"target_relabeled\"] = 0\n",
    "df_train.loc[df_train[\"text\"] == 'do you feel like you are sinking in low selfimage take the quiz', \"target_relabeled\"] = 0\n",
    "df_train.loc[df_train[\"text\"] == 'food scare offers to go nestle india slips into loss after magginoodle ban unsafe and hazardous for human consumption', \"target_relabeled\"] = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf568bc4-dd0b-477c-9d8e-5dee6d9495c2",
   "metadata": {},
   "source": [
    "#### Sending Cleaned Datasets to Data Folder:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "55c3be27-9960-4df9-98db-2aa3530a2205",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_cleanedMislabelsDuplicates = df_train[['id', 'keyword', 'location', 'text', 'target']]\n",
    "df_train_cleanedNoMislabelsDuplicates = df_train[['id', 'keyword', 'location', 'text', 'target_relabeled']]\n",
    "df_train_cleanedMislabelsNoDuplicates = df_train[['id', 'keyword', 'location', 'text', 'target']].drop_duplicates(subset='text', keep=\"first\")\n",
    "df_train_cleanedNoMislabelsNoDuplicates = df_train[['id', 'keyword', 'location', 'text', 'target_relabeled']].drop_duplicates(subset='text', keep=\"first\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "421c5159-abce-4c65-a68f-77a65918b526",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_cleanedMislabelsDuplicates.to_csv(\"../Data/df_train_cleanedMislabelsDuplicates.csv\", encoding='utf-8', index = False)\n",
    "df_train_cleanedNoMislabelsDuplicates.to_csv(\"../Data/df_train_cleanedNoMislabelsDuplicates.csv\", encoding='utf-8', index = False)\n",
    "df_train_cleanedMislabelsNoDuplicates.to_csv(\"../Data/df_train_cleanedMislabelsNoDuplicates.csv\", encoding='utf-8', index = False)\n",
    "df_train_cleanedNoMislabelsNoDuplicates.to_csv(\"../Data/df_train_cleanedNoMislabelsNoDuplicates.csv\", encoding='utf-8', index = False)\n",
    "df_test.to_csv(\"../Data/df_test_cleaned.csv\", encoding='utf-8', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98739311-5b7c-4b75-9a2e-3ecb06791b27",
   "metadata": {},
   "source": [
    "### Feature Creation:\n",
    "- word_count: number of words in text\n",
    "- unique_word_count: number of unique words in text\n",
    "- stop_word_count: number of stop words in text\n",
    "    - Could use nltk corpus or manual list you found online\n",
    "- url_count: number of urls in text\n",
    "- mean_word_length: average character count in words\n",
    "- mode_word_length: most common character count in words\n",
    "- char_count: number of characters in text\n",
    "- punctuation_count: number of punctuations in text\n",
    "- hashtag_count: number of hashtags (#) in text\n",
    "- emoji_count: dont know if dataset contains emojis, but if it does, might be a good idea to get a count of emojis\n",
    "- slang_word_count: count of slang words\n",
    "    - Need to figure out how I could make this\n",
    "- mention_count: number of mentions (@) in text\n",
    "- Create features based off unigrams, bigrams, and trigrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9824a018-449f-4479-ac3d-e4f4204bcadf",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'STOPWORDS' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[22], line 10\u001b[0m\n\u001b[0;32m      7\u001b[0m df_test[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124munique_word_count\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m df_test[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtext\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mapply(\u001b[38;5;28;01mlambda\u001b[39;00m x: \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mset\u001b[39m(\u001b[38;5;28mstr\u001b[39m(x)\u001b[38;5;241m.\u001b[39msplit())))\n\u001b[0;32m      9\u001b[0m \u001b[38;5;66;03m# stop_word_count\u001b[39;00m\n\u001b[1;32m---> 10\u001b[0m df_train[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstop_word_count\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43mdf_train\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtext\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mw\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mw\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlower\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplit\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mw\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mSTOPWORDS\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     11\u001b[0m df_test[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstop_word_count\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m df_test[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtext\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mapply(\u001b[38;5;28;01mlambda\u001b[39;00m x: \u001b[38;5;28mlen\u001b[39m([w \u001b[38;5;28;01mfor\u001b[39;00m w \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mstr\u001b[39m(x)\u001b[38;5;241m.\u001b[39mlower()\u001b[38;5;241m.\u001b[39msplit() \u001b[38;5;28;01mif\u001b[39;00m w \u001b[38;5;129;01min\u001b[39;00m STOPWORDS]))\n\u001b[0;32m     13\u001b[0m \u001b[38;5;66;03m# url_count\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\series.py:4771\u001b[0m, in \u001b[0;36mSeries.apply\u001b[1;34m(self, func, convert_dtype, args, **kwargs)\u001b[0m\n\u001b[0;32m   4661\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mapply\u001b[39m(\n\u001b[0;32m   4662\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   4663\u001b[0m     func: AggFuncType,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   4666\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m   4667\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m DataFrame \u001b[38;5;241m|\u001b[39m Series:\n\u001b[0;32m   4668\u001b[0m     \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   4669\u001b[0m \u001b[38;5;124;03m    Invoke function on values of Series.\u001b[39;00m\n\u001b[0;32m   4670\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   4769\u001b[0m \u001b[38;5;124;03m    dtype: float64\u001b[39;00m\n\u001b[0;32m   4770\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 4771\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mSeriesApply\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconvert_dtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\apply.py:1105\u001b[0m, in \u001b[0;36mSeriesApply.apply\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1102\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapply_str()\n\u001b[0;32m   1104\u001b[0m \u001b[38;5;66;03m# self.f is Callable\u001b[39;00m\n\u001b[1;32m-> 1105\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply_standard\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\apply.py:1156\u001b[0m, in \u001b[0;36mSeriesApply.apply_standard\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1154\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1155\u001b[0m         values \u001b[38;5;241m=\u001b[39m obj\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;28mobject\u001b[39m)\u001b[38;5;241m.\u001b[39m_values\n\u001b[1;32m-> 1156\u001b[0m         mapped \u001b[38;5;241m=\u001b[39m \u001b[43mlib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmap_infer\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1157\u001b[0m \u001b[43m            \u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1158\u001b[0m \u001b[43m            \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1159\u001b[0m \u001b[43m            \u001b[49m\u001b[43mconvert\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconvert_dtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1160\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1162\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(mapped) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(mapped[\u001b[38;5;241m0\u001b[39m], ABCSeries):\n\u001b[0;32m   1163\u001b[0m     \u001b[38;5;66;03m# GH#43986 Need to do list(mapped) in order to get treated as nested\u001b[39;00m\n\u001b[0;32m   1164\u001b[0m     \u001b[38;5;66;03m#  See also GH#25959 regarding EA support\u001b[39;00m\n\u001b[0;32m   1165\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m obj\u001b[38;5;241m.\u001b[39m_constructor_expanddim(\u001b[38;5;28mlist\u001b[39m(mapped), index\u001b[38;5;241m=\u001b[39mobj\u001b[38;5;241m.\u001b[39mindex)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\_libs\\lib.pyx:2918\u001b[0m, in \u001b[0;36mpandas._libs.lib.map_infer\u001b[1;34m()\u001b[0m\n",
      "Cell \u001b[1;32mIn[22], line 10\u001b[0m, in \u001b[0;36m<lambda>\u001b[1;34m(x)\u001b[0m\n\u001b[0;32m      7\u001b[0m df_test[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124munique_word_count\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m df_test[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtext\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mapply(\u001b[38;5;28;01mlambda\u001b[39;00m x: \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mset\u001b[39m(\u001b[38;5;28mstr\u001b[39m(x)\u001b[38;5;241m.\u001b[39msplit())))\n\u001b[0;32m      9\u001b[0m \u001b[38;5;66;03m# stop_word_count\u001b[39;00m\n\u001b[1;32m---> 10\u001b[0m df_train[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstop_word_count\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m df_train[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtext\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mapply(\u001b[38;5;28;01mlambda\u001b[39;00m x: \u001b[38;5;28mlen\u001b[39m([w \u001b[38;5;28;01mfor\u001b[39;00m w \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mstr\u001b[39m(x)\u001b[38;5;241m.\u001b[39mlower()\u001b[38;5;241m.\u001b[39msplit() \u001b[38;5;28;01mif\u001b[39;00m w \u001b[38;5;129;01min\u001b[39;00m STOPWORDS]))\n\u001b[0;32m     11\u001b[0m df_test[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstop_word_count\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m df_test[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtext\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mapply(\u001b[38;5;28;01mlambda\u001b[39;00m x: \u001b[38;5;28mlen\u001b[39m([w \u001b[38;5;28;01mfor\u001b[39;00m w \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mstr\u001b[39m(x)\u001b[38;5;241m.\u001b[39mlower()\u001b[38;5;241m.\u001b[39msplit() \u001b[38;5;28;01mif\u001b[39;00m w \u001b[38;5;129;01min\u001b[39;00m STOPWORDS]))\n\u001b[0;32m     13\u001b[0m \u001b[38;5;66;03m# url_count\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[22], line 10\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m      7\u001b[0m df_test[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124munique_word_count\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m df_test[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtext\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mapply(\u001b[38;5;28;01mlambda\u001b[39;00m x: \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mset\u001b[39m(\u001b[38;5;28mstr\u001b[39m(x)\u001b[38;5;241m.\u001b[39msplit())))\n\u001b[0;32m      9\u001b[0m \u001b[38;5;66;03m# stop_word_count\u001b[39;00m\n\u001b[1;32m---> 10\u001b[0m df_train[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstop_word_count\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m df_train[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtext\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mapply(\u001b[38;5;28;01mlambda\u001b[39;00m x: \u001b[38;5;28mlen\u001b[39m([w \u001b[38;5;28;01mfor\u001b[39;00m w \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mstr\u001b[39m(x)\u001b[38;5;241m.\u001b[39mlower()\u001b[38;5;241m.\u001b[39msplit() \u001b[38;5;28;01mif\u001b[39;00m w \u001b[38;5;129;01min\u001b[39;00m \u001b[43mSTOPWORDS\u001b[49m]))\n\u001b[0;32m     11\u001b[0m df_test[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstop_word_count\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m df_test[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtext\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mapply(\u001b[38;5;28;01mlambda\u001b[39;00m x: \u001b[38;5;28mlen\u001b[39m([w \u001b[38;5;28;01mfor\u001b[39;00m w \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mstr\u001b[39m(x)\u001b[38;5;241m.\u001b[39mlower()\u001b[38;5;241m.\u001b[39msplit() \u001b[38;5;28;01mif\u001b[39;00m w \u001b[38;5;129;01min\u001b[39;00m STOPWORDS]))\n\u001b[0;32m     13\u001b[0m \u001b[38;5;66;03m# url_count\u001b[39;00m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'STOPWORDS' is not defined"
     ]
    }
   ],
   "source": [
    "# word_count\n",
    "df_train['word_count'] = df_train['text'].apply(lambda x: len(str(x).split()))\n",
    "df_test['word_count'] = df_test['text'].apply(lambda x: len(str(x).split()))\n",
    "\n",
    "# unique_word_count\n",
    "df_train['unique_word_count'] = df_train['text'].apply(lambda x: len(set(str(x).split())))\n",
    "df_test['unique_word_count'] = df_test['text'].apply(lambda x: len(set(str(x).split())))\n",
    "\n",
    "# stop_word_count\n",
    "df_train['stop_word_count'] = df_train['text'].apply(lambda x: len([w for w in str(x).lower().split() if w in STOPWORDS]))\n",
    "df_test['stop_word_count'] = df_test['text'].apply(lambda x: len([w for w in str(x).lower().split() if w in STOPWORDS]))\n",
    "\n",
    "# url_count\n",
    "df_train['url_count'] = df_train['text'].apply(lambda x: len([w for w in str(x).lower().split() if 'http' in w or 'https' in w]))\n",
    "df_test['url_count'] = df_test['text'].apply(lambda x: len([w for w in str(x).lower().split() if 'http' in w or 'https' in w]))\n",
    "\n",
    "# mean_word_length\n",
    "df_train['mean_word_length'] = df_train['text'].apply(lambda x: np.mean([len(w) for w in str(x).split()]))\n",
    "df_test['mean_word_length'] = df_test['text'].apply(lambda x: np.mean([len(w) for w in str(x).split()]))\n",
    "\n",
    "# mode_word_length\n",
    "df_train['mode_word_length'] = df_train['text'].apply(lambda x: st.mode([len(w) for w in str(x).split()]))\n",
    "df_test['mode_word_length'] = df_test['text'].apply(lambda x: st.mode([len(w) for w in str(x).split()]))\n",
    "\n",
    "# median_word_length\n",
    "df_train['median_word_length'] = df_train['text'].apply(lambda x: np.median([len(w) for w in str(x).split()]))\n",
    "df_test['median_word_length'] = df_test['text'].apply(lambda x: np.median([len(w) for w in str(x).split()]))\n",
    "\n",
    "# char_count\n",
    "df_train['char_count'] = df_train['text'].apply(lambda x: len(str(x)))\n",
    "df_test['char_count'] = df_test['text'].apply(lambda x: len(str(x)))\n",
    "\n",
    "# punctuation_count\n",
    "df_train['punctuation_count'] = df_train['text'].apply(lambda x: len([c for c in str(x) if c in string.punctuation]))\n",
    "df_test['punctuation_count'] = df_test['text'].apply(lambda x: len([c for c in str(x) if c in string.punctuation]))\n",
    "\n",
    "# hashtag_count\n",
    "df_train['hashtag_count'] = df_train['text'].apply(lambda x: len([c for c in str(x) if c == '#']))\n",
    "df_test['hashtag_count'] = df_test['text'].apply(lambda x: len([c for c in str(x) if c == '#']))\n",
    "\n",
    "# mention_count\n",
    "df_train['mention_count'] = df_train['text'].apply(lambda x: len([c for c in str(x) if c == '@']))\n",
    "df_test['mention_count'] = df_test['text'].apply(lambda x: len([c for c in str(x) if c == '@']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13a06c18-b2f1-4d4e-b428-dc643ac939bd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
